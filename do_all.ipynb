{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3c3507",
   "metadata": {},
   "source": [
    "# Lets first get our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eddb80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa==0.6 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (0.6.0)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from librosa==0.6) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from librosa==0.6) (1.19.5)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from librosa==0.6) (3.0.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from librosa==0.6) (5.0.9)\n",
      "Requirement already satisfied: six>=1.3 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from librosa==0.6) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from librosa==0.6) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.7.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from librosa==0.6) (1.1.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from librosa==0.6) (1.5.4)\n",
      "Collecting numba>=0.53\n",
      "  Using cached numba-0.53.1-cp36-cp36m-manylinux2014_x86_64.whl (3.4 MB)\n",
      "Requirement already satisfied: setuptools in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from numba>=0.53->resampy>=0.2.0->librosa==0.6) (58.0.2)\n",
      "Collecting llvmlite<0.37,>=0.36.0rc1\n",
      "  Using cached llvmlite-0.36.0-cp36-cp36m-manylinux2010_x86_64.whl (25.3 MB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.6) (3.1.0)\n",
      "Installing collected packages: llvmlite, numba\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.31.0\n",
      "    Uninstalling llvmlite-0.31.0:\n",
      "      Successfully uninstalled llvmlite-0.31.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.48.0\n",
      "    Uninstalling numba-0.48.0:\n",
      "      Successfully uninstalled numba-0.48.0\n",
      "Successfully installed llvmlite-0.36.0 numba-0.53.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ecbm4040/envTF24/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numba==0.48\n",
      "  Using cached numba-0.48.0-1-cp36-cp36m-manylinux2014_x86_64.whl (3.5 MB)\n",
      "Requirement already satisfied: setuptools in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from numba==0.48) (58.0.2)\n",
      "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
      "  Using cached llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from numba==0.48) (1.19.5)\n",
      "Installing collected packages: llvmlite, numba\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.36.0\n",
      "    Uninstalling llvmlite-0.36.0:\n",
      "      Successfully uninstalled llvmlite-0.36.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.53.1\n",
      "    Uninstalling numba-0.53.1:\n",
      "      Successfully uninstalled numba-0.53.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "resampy 0.4.2 requires numba>=0.53, but you have numba 0.48.0 which is incompatible.\u001b[0m\n",
      "Successfully installed llvmlite-0.31.0 numba-0.48.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ecbm4040/envTF24/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow==1.8 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (1.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorflow==1.8) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorflow==1.8) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorflow==1.8) (0.13.0)\n",
      "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorflow==1.8) (1.8.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorflow==1.8) (0.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorflow==1.8) (0.37.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorflow==1.8) (1.19.5)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorflow==1.8) (0.3.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorflow==1.8) (1.32.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorflow==1.8) (3.17.3)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (0.9999999)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (2.0.1)\n",
      "Requirement already satisfied: bleach==1.5.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (1.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (3.3.4)\n",
      "Requirement already satisfied: importlib-metadata in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (4.8.1)\n",
      "Requirement already satisfied: dataclasses in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from werkzeug>=0.11.10->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (3.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ecbm4040/envTF24/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting resampy==0.3.1\n",
      "  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.47 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from resampy==0.3.1) (0.48.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from resampy==0.3.1) (1.19.5)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from numba>=0.47->resampy==0.3.1) (0.31.0)\n",
      "Requirement already satisfied: setuptools in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from numba>=0.47->resampy==0.3.1) (58.0.2)\n",
      "Installing collected packages: resampy\n",
      "  Attempting uninstall: resampy\n",
      "    Found existing installation: resampy 0.4.2\n",
      "    Uninstalling resampy-0.4.2:\n",
      "      Successfully uninstalled resampy-0.4.2\n",
      "Successfully installed resampy-0.3.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ecbm4040/envTF24/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nreplace \"import tensorflow as tf\" with\\nimport tensorflow.compat.v1 as tf\\ntf.disable_v2_behavior()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install librosa==0.6\n",
    "!pip install numba==0.48\n",
    "!pip install tensorflow==1.8\n",
    "!pip install resampy==0.3.1\n",
    "#or run requirements.txt\n",
    "\n",
    "# IN bash: sudo apt-get install libsndfile1\n",
    "\"\"\"\n",
    "sudo apt update\n",
    "sudo apt install ffmpeg\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d1a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "def download_and_unzip(url, extract_to='.'):\n",
    "    http_response = urlopen(url)\n",
    "    zipfile = ZipFile(BytesIO(http_response.read()))\n",
    "    zipfile.extractall(path=extract_to)\n",
    "    \n",
    "\n",
    "download_and_unzip(url = 'http://mirlab.org/dataset/public/MIR-1K.zip',extract_to = './download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50406f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train test split\n",
    "!python download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca913183",
   "metadata": {},
   "source": [
    "# Train if Needed\n",
    "You need to move files around!\n",
    "You will have to put: train.txt, test.txt, and valid.txt in nndl_SING/data/MIR1K\n",
    "The Original Unzipped Files (Lyrics, LyricsWav etc) in to the folder: nndl_SING/data/MIR-1K\n",
    "Notice there are 2 distint folder here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a560de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2022-12-17 21:49:43.624566: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "Step: 0 Train Loss: 9.635193\n",
      "==============================================\n",
      "Step: 0 Validation Loss: 8.448767\n",
      "==============================================\n",
      "Step: 10 Train Loss: 8.257599\n",
      "Step: 20 Train Loss: 5.622697\n",
      "Step: 30 Train Loss: 5.617909\n",
      "Step: 40 Train Loss: 4.606820\n",
      "Step: 50 Train Loss: 4.484491\n",
      "Step: 60 Train Loss: 4.517666\n",
      "Step: 70 Train Loss: 3.664326\n",
      "Step: 80 Train Loss: 4.134757\n",
      "Step: 90 Train Loss: 3.971286\n",
      "Step: 100 Train Loss: 4.023190\n",
      "Step: 110 Train Loss: 3.288252\n",
      "Step: 120 Train Loss: 3.951419\n",
      "Step: 130 Train Loss: 3.539536\n",
      "Step: 140 Train Loss: 3.962672\n",
      "Step: 150 Train Loss: 3.759814\n",
      "Step: 160 Train Loss: 4.544341\n",
      "Step: 170 Train Loss: 3.168253\n",
      "Step: 180 Train Loss: 3.295504\n",
      "Step: 190 Train Loss: 2.840644\n",
      "Step: 200 Train Loss: 3.397782\n",
      "==============================================\n",
      "Step: 200 Validation Loss: 4.070910\n",
      "==============================================\n",
      "Step: 210 Train Loss: 2.966649\n",
      "Step: 220 Train Loss: 3.639107\n",
      "Step: 230 Train Loss: 3.295653\n",
      "Step: 240 Train Loss: 2.710279\n",
      "Step: 250 Train Loss: 3.197956\n",
      "Step: 260 Train Loss: 3.945613\n",
      "Step: 270 Train Loss: 2.908012\n",
      "Step: 280 Train Loss: 2.677480\n",
      "Step: 290 Train Loss: 3.500343\n",
      "Step: 300 Train Loss: 3.640017\n",
      "Step: 310 Train Loss: 2.474859\n",
      "Step: 320 Train Loss: 3.381116\n",
      "Step: 330 Train Loss: 2.939198\n",
      "Step: 340 Train Loss: 2.411223\n",
      "Step: 350 Train Loss: 2.857461\n",
      "Step: 360 Train Loss: 2.577314\n",
      "Step: 370 Train Loss: 3.143662\n",
      "Step: 380 Train Loss: 2.919828\n",
      "Step: 390 Train Loss: 2.813583\n",
      "Step: 400 Train Loss: 3.386661\n",
      "==============================================\n",
      "Step: 400 Validation Loss: 3.637450\n",
      "==============================================\n",
      "Step: 410 Train Loss: 3.315297\n",
      "Step: 420 Train Loss: 3.056514\n",
      "Step: 430 Train Loss: 2.594216\n",
      "Step: 440 Train Loss: 2.530468\n",
      "Step: 450 Train Loss: 3.000597\n",
      "Step: 460 Train Loss: 3.234206\n",
      "Step: 470 Train Loss: 3.224822\n",
      "Step: 480 Train Loss: 2.583822\n",
      "Step: 490 Train Loss: 2.531096\n",
      "Step: 500 Train Loss: 2.871381\n",
      "Step: 510 Train Loss: 2.328671\n",
      "Step: 520 Train Loss: 2.804010\n",
      "Step: 530 Train Loss: 2.550986\n",
      "Step: 540 Train Loss: 2.752288\n",
      "Step: 550 Train Loss: 2.983999\n",
      "Step: 560 Train Loss: 3.062921\n",
      "Step: 570 Train Loss: 2.977489\n",
      "Step: 580 Train Loss: 2.030539\n",
      "Step: 590 Train Loss: 2.657665\n",
      "Step: 600 Train Loss: 2.848874\n",
      "==============================================\n",
      "Step: 600 Validation Loss: 3.008737\n",
      "==============================================\n",
      "Step: 610 Train Loss: 2.517727\n",
      "Step: 620 Train Loss: 2.304384\n",
      "Step: 630 Train Loss: 3.010961\n",
      "Step: 640 Train Loss: 3.120148\n",
      "Step: 650 Train Loss: 2.577399\n",
      "Step: 660 Train Loss: 2.773536\n",
      "Step: 670 Train Loss: 2.596537\n",
      "Step: 680 Train Loss: 3.063906\n",
      "Step: 690 Train Loss: 2.648715\n",
      "Step: 700 Train Loss: 2.596261\n",
      "Step: 710 Train Loss: 2.418144\n",
      "Step: 720 Train Loss: 2.541423\n",
      "Step: 730 Train Loss: 2.704549\n",
      "Step: 740 Train Loss: 1.953509\n",
      "Step: 750 Train Loss: 2.415630\n",
      "Step: 760 Train Loss: 2.351625\n",
      "Step: 770 Train Loss: 2.413210\n",
      "Step: 780 Train Loss: 2.006754\n",
      "Step: 790 Train Loss: 1.978466\n",
      "Step: 800 Train Loss: 2.168665\n",
      "==============================================\n",
      "Step: 800 Validation Loss: 2.656808\n",
      "==============================================\n",
      "Step: 810 Train Loss: 2.383939\n",
      "Step: 820 Train Loss: 2.460474\n",
      "Step: 830 Train Loss: 3.457529\n",
      "Step: 840 Train Loss: 2.174186\n",
      "Step: 850 Train Loss: 2.451215\n",
      "Step: 860 Train Loss: 2.118903\n",
      "Step: 870 Train Loss: 2.649984\n",
      "Step: 880 Train Loss: 2.016248\n",
      "Step: 890 Train Loss: 2.316477\n",
      "Step: 900 Train Loss: 2.371427\n",
      "Step: 910 Train Loss: 2.452106\n",
      "Step: 920 Train Loss: 2.437445\n",
      "Step: 930 Train Loss: 2.663927\n",
      "Step: 940 Train Loss: 2.309158\n",
      "Step: 950 Train Loss: 2.518953\n",
      "Step: 960 Train Loss: 2.628197\n",
      "Step: 970 Train Loss: 3.320832\n",
      "Step: 980 Train Loss: 1.973361\n",
      "Step: 990 Train Loss: 3.031168\n",
      "Step: 1000 Train Loss: 2.097914\n",
      "==============================================\n",
      "Step: 1000 Validation Loss: 3.174750\n",
      "==============================================\n",
      "Step: 1010 Train Loss: 2.294036\n",
      "Step: 1020 Train Loss: 2.259262\n",
      "Step: 1030 Train Loss: 2.748193\n",
      "Step: 1040 Train Loss: 2.531238\n",
      "Step: 1050 Train Loss: 2.130646\n",
      "Step: 1060 Train Loss: 2.379117\n",
      "Step: 1070 Train Loss: 1.803639\n",
      "Step: 1080 Train Loss: 2.189402\n",
      "Step: 1090 Train Loss: 2.093407\n",
      "Step: 1100 Train Loss: 2.754122\n",
      "Step: 1110 Train Loss: 2.419549\n",
      "Step: 1120 Train Loss: 1.954905\n",
      "Step: 1130 Train Loss: 2.295045\n",
      "Step: 1140 Train Loss: 1.766757\n",
      "Step: 1150 Train Loss: 1.847581\n",
      "Step: 1160 Train Loss: 2.223501\n",
      "Step: 1170 Train Loss: 1.714702\n",
      "Step: 1180 Train Loss: 2.383349\n",
      "Step: 1190 Train Loss: 1.913863\n",
      "Step: 1200 Train Loss: 1.871832\n",
      "==============================================\n",
      "Step: 1200 Validation Loss: 2.736095\n",
      "==============================================\n",
      "Step: 1210 Train Loss: 1.923748\n",
      "Step: 1220 Train Loss: 1.937907\n",
      "Step: 1230 Train Loss: 2.023605\n",
      "Step: 1240 Train Loss: 2.146704\n",
      "Step: 1250 Train Loss: 2.297318\n",
      "Step: 1260 Train Loss: 1.866059\n",
      "Step: 1270 Train Loss: 2.179809\n",
      "Step: 1280 Train Loss: 2.030267\n",
      "Step: 1290 Train Loss: 1.893140\n",
      "Step: 1300 Train Loss: 2.705190\n",
      "Step: 1310 Train Loss: 2.303834\n",
      "Step: 1320 Train Loss: 2.427459\n",
      "Step: 1330 Train Loss: 1.988512\n",
      "Step: 1340 Train Loss: 2.116700\n",
      "Step: 1350 Train Loss: 1.963261\n",
      "Step: 1360 Train Loss: 1.747420\n",
      "Step: 1370 Train Loss: 2.037941\n",
      "Step: 1380 Train Loss: 2.161962\n",
      "Step: 1390 Train Loss: 2.218611\n",
      "Step: 1400 Train Loss: 2.003161\n",
      "==============================================\n",
      "Step: 1400 Validation Loss: 2.339974\n",
      "==============================================\n",
      "Step: 1410 Train Loss: 2.110445\n",
      "Step: 1420 Train Loss: 1.857404\n",
      "Step: 1430 Train Loss: 2.142579\n",
      "Step: 1440 Train Loss: 1.870721\n",
      "Step: 1450 Train Loss: 1.947913\n",
      "Step: 1460 Train Loss: 1.607763\n",
      "Step: 1470 Train Loss: 2.081627\n",
      "Step: 1480 Train Loss: 1.752154\n",
      "Step: 1490 Train Loss: 2.323078\n",
      "Step: 1500 Train Loss: 1.799041\n",
      "Step: 1510 Train Loss: 1.760291\n",
      "Step: 1520 Train Loss: 1.866094\n",
      "Step: 1530 Train Loss: 2.729051\n",
      "Step: 1540 Train Loss: 2.236472\n",
      "Step: 1550 Train Loss: 2.108434\n",
      "Step: 1560 Train Loss: 1.963462\n",
      "Step: 1570 Train Loss: 1.922930\n",
      "Step: 1580 Train Loss: 1.566227\n",
      "Step: 1590 Train Loss: 2.316123\n",
      "Step: 1600 Train Loss: 1.682648\n",
      "==============================================\n",
      "Step: 1600 Validation Loss: 3.060720\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1610 Train Loss: 1.865051\n",
      "Step: 1620 Train Loss: 1.789449\n",
      "Step: 1630 Train Loss: 1.928974\n",
      "Step: 1640 Train Loss: 1.793582\n",
      "Step: 1650 Train Loss: 1.624317\n",
      "Step: 1660 Train Loss: 1.920552\n",
      "Step: 1670 Train Loss: 2.162628\n",
      "Step: 1680 Train Loss: 1.691685\n",
      "Step: 1690 Train Loss: 1.990360\n",
      "Step: 1700 Train Loss: 1.685972\n",
      "Step: 1710 Train Loss: 1.974059\n",
      "Step: 1720 Train Loss: 1.932527\n",
      "Step: 1730 Train Loss: 1.726270\n",
      "Step: 1740 Train Loss: 1.811085\n",
      "Step: 1750 Train Loss: 2.005909\n",
      "Step: 1760 Train Loss: 1.444956\n",
      "Step: 1770 Train Loss: 2.117089\n",
      "Step: 1780 Train Loss: 1.867877\n",
      "Step: 1790 Train Loss: 1.976712\n",
      "Step: 1800 Train Loss: 2.015224\n",
      "==============================================\n",
      "Step: 1800 Validation Loss: 2.628163\n",
      "==============================================\n",
      "Step: 1810 Train Loss: 2.061099\n",
      "Step: 1820 Train Loss: 1.817364\n",
      "Step: 1830 Train Loss: 1.938154\n",
      "Step: 1840 Train Loss: 1.702561\n",
      "Step: 1850 Train Loss: 1.807152\n",
      "Step: 1860 Train Loss: 1.884361\n",
      "Step: 1870 Train Loss: 1.887356\n",
      "Step: 1880 Train Loss: 1.735094\n",
      "Step: 1890 Train Loss: 1.925124\n",
      "Step: 1900 Train Loss: 1.744870\n",
      "Step: 1910 Train Loss: 1.760221\n",
      "Step: 1920 Train Loss: 1.935613\n",
      "Step: 1930 Train Loss: 1.702047\n",
      "Step: 1940 Train Loss: 2.000405\n",
      "Step: 1950 Train Loss: 1.638437\n",
      "Step: 1960 Train Loss: 2.591568\n",
      "Step: 1970 Train Loss: 1.572678\n",
      "Step: 1980 Train Loss: 1.842231\n",
      "Step: 1990 Train Loss: 2.063207\n",
      "Step: 2000 Train Loss: 1.646621\n",
      "==============================================\n",
      "Step: 2000 Validation Loss: 3.089229\n",
      "==============================================\n",
      "Step: 2010 Train Loss: 1.856182\n",
      "Step: 2020 Train Loss: 2.081222\n",
      "Step: 2030 Train Loss: 1.770679\n",
      "Step: 2040 Train Loss: 1.775256\n",
      "Step: 2050 Train Loss: 1.526583\n",
      "Step: 2060 Train Loss: 1.591606\n",
      "Step: 2070 Train Loss: 2.040153\n",
      "Step: 2080 Train Loss: 1.470466\n",
      "Step: 2090 Train Loss: 1.948754\n",
      "Step: 2100 Train Loss: 1.605980\n",
      "Step: 2110 Train Loss: 1.844638\n",
      "Step: 2120 Train Loss: 1.856546\n",
      "Step: 2130 Train Loss: 1.681485\n",
      "Step: 2140 Train Loss: 1.784297\n",
      "Step: 2150 Train Loss: 1.888861\n",
      "Step: 2160 Train Loss: 1.468124\n",
      "Step: 2170 Train Loss: 1.939782\n",
      "Step: 2180 Train Loss: 1.526199\n",
      "Step: 2190 Train Loss: 1.870822\n",
      "Step: 2200 Train Loss: 1.885589\n",
      "==============================================\n",
      "Step: 2200 Validation Loss: 2.840865\n",
      "==============================================\n",
      "Step: 2210 Train Loss: 2.029364\n",
      "Step: 2220 Train Loss: 2.139544\n",
      "Step: 2230 Train Loss: 1.592436\n",
      "Step: 2240 Train Loss: 1.404013\n",
      "Step: 2250 Train Loss: 1.973309\n",
      "Step: 2260 Train Loss: 1.606573\n",
      "Step: 2270 Train Loss: 1.547698\n",
      "Step: 2280 Train Loss: 1.787106\n",
      "Step: 2290 Train Loss: 1.609591\n",
      "Step: 2300 Train Loss: 1.916351\n",
      "Step: 2310 Train Loss: 1.613574\n",
      "Step: 2320 Train Loss: 1.540481\n",
      "Step: 2330 Train Loss: 1.852992\n",
      "Step: 2340 Train Loss: 1.972232\n",
      "Step: 2350 Train Loss: 1.688375\n",
      "Step: 2360 Train Loss: 1.812889\n",
      "Step: 2370 Train Loss: 1.502602\n",
      "Step: 2380 Train Loss: 1.960196\n",
      "Step: 2390 Train Loss: 2.016251\n",
      "Step: 2400 Train Loss: 1.695509\n",
      "==============================================\n",
      "Step: 2400 Validation Loss: 2.460356\n",
      "==============================================\n",
      "Step: 2410 Train Loss: 1.532918\n",
      "Step: 2420 Train Loss: 1.589042\n",
      "Step: 2430 Train Loss: 1.451776\n",
      "Step: 2440 Train Loss: 1.760961\n",
      "Step: 2450 Train Loss: 1.230447\n",
      "Step: 2460 Train Loss: 1.510139\n",
      "Step: 2470 Train Loss: 2.302017\n",
      "Step: 2480 Train Loss: 1.512640\n",
      "Step: 2490 Train Loss: 1.247346\n",
      "Step: 2500 Train Loss: 1.672274\n",
      "Step: 2510 Train Loss: 1.726635\n",
      "Step: 2520 Train Loss: 1.720462\n",
      "Step: 2530 Train Loss: 1.446479\n",
      "Step: 2540 Train Loss: 1.711919\n",
      "Step: 2550 Train Loss: 1.383464\n",
      "Step: 2560 Train Loss: 1.590761\n",
      "Step: 2570 Train Loss: 1.662098\n",
      "Step: 2580 Train Loss: 1.967341\n",
      "Step: 2590 Train Loss: 1.760708\n",
      "Step: 2600 Train Loss: 1.839325\n",
      "==============================================\n",
      "Step: 2600 Validation Loss: 2.773327\n",
      "==============================================\n",
      "Step: 2610 Train Loss: 1.665725\n",
      "Step: 2620 Train Loss: 1.559178\n",
      "Step: 2630 Train Loss: 1.856087\n",
      "Step: 2640 Train Loss: 1.496625\n",
      "Step: 2650 Train Loss: 1.623312\n",
      "Step: 2660 Train Loss: 1.505895\n",
      "Step: 2670 Train Loss: 1.914109\n",
      "Step: 2680 Train Loss: 1.737495\n",
      "Step: 2690 Train Loss: 1.679744\n",
      "Step: 2700 Train Loss: 1.447681\n",
      "Step: 2710 Train Loss: 1.488374\n",
      "Step: 2720 Train Loss: 1.671074\n",
      "Step: 2730 Train Loss: 1.655923\n",
      "Step: 2740 Train Loss: 1.786088\n",
      "Step: 2750 Train Loss: 1.731749\n",
      "Step: 2760 Train Loss: 1.396050\n",
      "Step: 2770 Train Loss: 1.665021\n",
      "Step: 2780 Train Loss: 1.688159\n",
      "Step: 2790 Train Loss: 1.716645\n",
      "Step: 2800 Train Loss: 1.415429\n",
      "==============================================\n",
      "Step: 2800 Validation Loss: 2.644545\n",
      "==============================================\n",
      "Step: 2810 Train Loss: 1.493656\n",
      "Step: 2820 Train Loss: 1.662527\n",
      "Step: 2830 Train Loss: 1.330270\n",
      "Step: 2840 Train Loss: 1.583270\n",
      "Step: 2850 Train Loss: 1.470194\n",
      "Step: 2860 Train Loss: 1.800198\n",
      "Step: 2870 Train Loss: 1.585313\n",
      "Step: 2880 Train Loss: 1.373857\n",
      "Step: 2890 Train Loss: 1.596043\n",
      "Step: 2900 Train Loss: 1.439583\n",
      "Step: 2910 Train Loss: 1.744021\n",
      "Step: 2920 Train Loss: 1.861021\n",
      "Step: 2930 Train Loss: 1.924000\n",
      "Step: 2940 Train Loss: 1.696056\n",
      "Step: 2950 Train Loss: 1.508703\n",
      "Step: 2960 Train Loss: 1.693653\n",
      "Step: 2970 Train Loss: 1.581140\n",
      "Step: 2980 Train Loss: 1.592633\n",
      "Step: 2990 Train Loss: 1.513159\n",
      "Step: 3000 Train Loss: 1.610479\n",
      "==============================================\n",
      "Step: 3000 Validation Loss: 1.913840\n",
      "==============================================\n",
      "Step: 3010 Train Loss: 1.377534\n",
      "Step: 3020 Train Loss: 1.755693\n",
      "Step: 3030 Train Loss: 1.326272\n",
      "Step: 3040 Train Loss: 1.526343\n",
      "Step: 3050 Train Loss: 1.719963\n",
      "Step: 3060 Train Loss: 1.654623\n",
      "Step: 3070 Train Loss: 1.515304\n",
      "Step: 3080 Train Loss: 1.582969\n",
      "Step: 3090 Train Loss: 1.721790\n",
      "Step: 3100 Train Loss: 1.603855\n",
      "Step: 3110 Train Loss: 1.679765\n",
      "Step: 3120 Train Loss: 1.292374\n",
      "Step: 3130 Train Loss: 1.455673\n",
      "Step: 3140 Train Loss: 1.592602\n",
      "Step: 3150 Train Loss: 1.725950\n",
      "Step: 3160 Train Loss: 1.509764\n",
      "Step: 3170 Train Loss: 1.717207\n",
      "Step: 3180 Train Loss: 1.573657\n",
      "Step: 3190 Train Loss: 1.452702\n",
      "Step: 3200 Train Loss: 1.492734\n",
      "==============================================\n",
      "Step: 3200 Validation Loss: 1.814976\n",
      "==============================================\n",
      "Step: 3210 Train Loss: 1.556136\n",
      "Step: 3220 Train Loss: 1.659433\n",
      "Step: 3230 Train Loss: 1.802404\n",
      "Step: 3240 Train Loss: 1.876776\n",
      "Step: 3250 Train Loss: 1.715509\n",
      "Step: 3260 Train Loss: 1.544427\n",
      "Step: 3270 Train Loss: 1.662403\n",
      "Step: 3280 Train Loss: 1.605675\n",
      "Step: 3290 Train Loss: 1.682219\n",
      "Step: 3300 Train Loss: 1.638267\n",
      "Step: 3310 Train Loss: 1.390916\n",
      "Step: 3320 Train Loss: 1.862450\n",
      "Step: 3330 Train Loss: 1.262500\n",
      "Step: 3340 Train Loss: 1.671945\n",
      "Step: 3350 Train Loss: 1.379551\n",
      "Step: 3360 Train Loss: 1.446472\n",
      "Step: 3370 Train Loss: 1.576521\n",
      "Step: 3380 Train Loss: 1.804999\n",
      "Step: 3390 Train Loss: 1.791129\n",
      "Step: 3400 Train Loss: 1.613479\n",
      "==============================================\n",
      "Step: 3400 Validation Loss: 2.261772\n",
      "==============================================\n",
      "Step: 3410 Train Loss: 1.425138\n",
      "Step: 3420 Train Loss: 1.560158\n",
      "Step: 3430 Train Loss: 1.566460\n",
      "Step: 3440 Train Loss: 1.584858\n",
      "Step: 3450 Train Loss: 1.031606\n",
      "Step: 3460 Train Loss: 1.334309\n",
      "Step: 3470 Train Loss: 1.352782\n",
      "Step: 3480 Train Loss: 1.898823\n",
      "Step: 3490 Train Loss: 1.492956\n",
      "Step: 3500 Train Loss: 1.692521\n",
      "Step: 3510 Train Loss: 1.272012\n",
      "Step: 3520 Train Loss: 1.537461\n",
      "Step: 3530 Train Loss: 1.685069\n",
      "Step: 3540 Train Loss: 1.742460\n",
      "Step: 3550 Train Loss: 1.711450\n",
      "Step: 3560 Train Loss: 1.360246\n",
      "Step: 3570 Train Loss: 1.509533\n",
      "Step: 3580 Train Loss: 1.534070\n",
      "Step: 3590 Train Loss: 1.625728\n",
      "Step: 3600 Train Loss: 1.552604\n",
      "==============================================\n",
      "Step: 3600 Validation Loss: 2.237060\n",
      "==============================================\n",
      "Step: 3610 Train Loss: 1.568263\n",
      "Step: 3620 Train Loss: 1.706182\n",
      "Step: 3630 Train Loss: 1.401019\n",
      "Step: 3640 Train Loss: 1.633241\n",
      "Step: 3650 Train Loss: 1.457688\n",
      "Step: 3660 Train Loss: 1.374287\n",
      "Step: 3670 Train Loss: 1.414048\n",
      "Step: 3680 Train Loss: 1.444743\n",
      "Step: 3690 Train Loss: 1.647380\n",
      "Step: 3700 Train Loss: 1.864637\n",
      "Step: 3710 Train Loss: 1.539288\n",
      "Step: 3720 Train Loss: 1.650317\n",
      "Step: 3730 Train Loss: 1.498067\n",
      "Step: 3740 Train Loss: 1.566861\n",
      "Step: 3750 Train Loss: 1.782761\n",
      "Step: 3760 Train Loss: 1.248222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3770 Train Loss: 1.265994\n",
      "Step: 3780 Train Loss: 1.541785\n",
      "Step: 3790 Train Loss: 1.628910\n",
      "Step: 3800 Train Loss: 1.279091\n",
      "==============================================\n",
      "Step: 3800 Validation Loss: 2.154243\n",
      "==============================================\n",
      "Step: 3810 Train Loss: 1.646243\n",
      "Step: 3820 Train Loss: 1.467382\n",
      "Step: 3830 Train Loss: 1.469779\n",
      "Step: 3840 Train Loss: 1.470600\n",
      "Step: 3850 Train Loss: 1.731205\n",
      "Step: 3860 Train Loss: 1.472014\n",
      "Step: 3870 Train Loss: 1.789912\n",
      "Step: 3880 Train Loss: 1.404631\n",
      "Step: 3890 Train Loss: 1.371904\n",
      "Step: 3900 Train Loss: 1.529185\n",
      "Step: 3910 Train Loss: 1.241150\n",
      "Step: 3920 Train Loss: 1.540258\n",
      "Step: 3930 Train Loss: 1.369940\n",
      "Step: 3940 Train Loss: 1.614539\n",
      "Step: 3950 Train Loss: 1.525716\n",
      "Step: 3960 Train Loss: 1.248587\n",
      "Step: 3970 Train Loss: 1.742773\n",
      "Step: 3980 Train Loss: 1.384659\n",
      "Step: 3990 Train Loss: 1.630659\n",
      "Step: 4000 Train Loss: 1.670287\n",
      "==============================================\n",
      "Step: 4000 Validation Loss: 2.917640\n",
      "==============================================\n",
      "Step: 4010 Train Loss: 1.645788\n",
      "Step: 4020 Train Loss: 1.229547\n",
      "Step: 4030 Train Loss: 1.135714\n",
      "Step: 4040 Train Loss: 1.325994\n",
      "Step: 4050 Train Loss: 1.234207\n",
      "Step: 4060 Train Loss: 1.518059\n",
      "Step: 4070 Train Loss: 1.375837\n",
      "Step: 4080 Train Loss: 1.285647\n",
      "Step: 4090 Train Loss: 1.579355\n",
      "Step: 4100 Train Loss: 1.440612\n",
      "Step: 4110 Train Loss: 1.775867\n",
      "Step: 4120 Train Loss: 1.856069\n",
      "Step: 4130 Train Loss: 1.689375\n",
      "Step: 4140 Train Loss: 1.525648\n",
      "Step: 4150 Train Loss: 1.449546\n",
      "Step: 4160 Train Loss: 1.324424\n",
      "Step: 4170 Train Loss: 1.357602\n",
      "Step: 4180 Train Loss: 1.560175\n",
      "Step: 4190 Train Loss: 1.482669\n",
      "Step: 4200 Train Loss: 1.125575\n",
      "==============================================\n",
      "Step: 4200 Validation Loss: 2.221243\n",
      "==============================================\n",
      "Step: 4210 Train Loss: 1.241772\n",
      "Step: 4220 Train Loss: 1.253565\n",
      "Step: 4230 Train Loss: 1.447843\n",
      "Step: 4240 Train Loss: 1.524999\n",
      "Step: 4250 Train Loss: 1.420304\n",
      "Step: 4260 Train Loss: 1.701035\n",
      "Step: 4270 Train Loss: 1.287502\n",
      "Step: 4280 Train Loss: 1.523348\n",
      "Step: 4290 Train Loss: 1.757707\n",
      "Step: 4300 Train Loss: 1.364911\n",
      "Step: 4310 Train Loss: 1.195604\n",
      "Step: 4320 Train Loss: 1.446474\n",
      "Step: 4330 Train Loss: 1.715310\n",
      "Step: 4340 Train Loss: 1.335024\n",
      "Step: 4350 Train Loss: 1.342208\n",
      "Step: 4360 Train Loss: 1.517244\n",
      "Step: 4370 Train Loss: 1.626592\n",
      "Step: 4380 Train Loss: 1.155567\n",
      "Step: 4390 Train Loss: 1.549055\n",
      "Step: 4400 Train Loss: 1.322409\n",
      "==============================================\n",
      "Step: 4400 Validation Loss: 2.505046\n",
      "==============================================\n",
      "Step: 4410 Train Loss: 1.517442\n",
      "Step: 4420 Train Loss: 1.699385\n",
      "Step: 4430 Train Loss: 1.640953\n",
      "Step: 4440 Train Loss: 1.840585\n",
      "Step: 4450 Train Loss: 1.423329\n",
      "Step: 4460 Train Loss: 1.548043\n",
      "Step: 4470 Train Loss: 1.671803\n",
      "Step: 4480 Train Loss: 1.526875\n",
      "Step: 4490 Train Loss: 1.625432\n",
      "Step: 4500 Train Loss: 1.727118\n",
      "Step: 4510 Train Loss: 1.771015\n",
      "Step: 4520 Train Loss: 1.575360\n",
      "Step: 4530 Train Loss: 1.275521\n",
      "Step: 4540 Train Loss: 1.350797\n",
      "Step: 4550 Train Loss: 1.449927\n",
      "Step: 4560 Train Loss: 1.104137\n",
      "Step: 4570 Train Loss: 1.298267\n",
      "Step: 4580 Train Loss: 1.594386\n",
      "Step: 4590 Train Loss: 1.493070\n",
      "Step: 4600 Train Loss: 1.451041\n",
      "==============================================\n",
      "Step: 4600 Validation Loss: 2.867770\n",
      "==============================================\n",
      "Step: 4610 Train Loss: 1.632594\n",
      "Step: 4620 Train Loss: 1.425090\n",
      "Step: 4630 Train Loss: 1.203622\n",
      "Step: 4640 Train Loss: 1.307012\n",
      "Step: 4650 Train Loss: 1.674330\n",
      "Step: 4660 Train Loss: 1.268116\n",
      "Step: 4670 Train Loss: 1.236583\n",
      "Step: 4680 Train Loss: 1.612099\n",
      "Step: 4690 Train Loss: 1.385819\n",
      "Step: 4700 Train Loss: 1.448799\n",
      "Step: 4710 Train Loss: 1.530635\n",
      "Step: 4720 Train Loss: 1.352921\n",
      "Step: 4730 Train Loss: 1.356355\n",
      "Step: 4740 Train Loss: 1.215296\n",
      "Step: 4750 Train Loss: 1.408019\n",
      "Step: 4760 Train Loss: 1.449992\n",
      "Step: 4770 Train Loss: 1.278826\n",
      "Step: 4780 Train Loss: 1.534905\n",
      "Step: 4790 Train Loss: 1.327915\n",
      "Step: 4800 Train Loss: 1.272284\n",
      "==============================================\n",
      "Step: 4800 Validation Loss: 2.255293\n",
      "==============================================\n",
      "Step: 4810 Train Loss: 1.714024\n",
      "Step: 4820 Train Loss: 1.366706\n",
      "Step: 4830 Train Loss: 1.364262\n",
      "Step: 4840 Train Loss: 1.394033\n",
      "Step: 4850 Train Loss: 1.099000\n",
      "Step: 4860 Train Loss: 1.156962\n",
      "Step: 4870 Train Loss: 1.255402\n",
      "Step: 4880 Train Loss: 1.224310\n",
      "Step: 4890 Train Loss: 1.229653\n",
      "Step: 4900 Train Loss: 1.190096\n",
      "Step: 4910 Train Loss: 1.606108\n",
      "Step: 4920 Train Loss: 1.238560\n",
      "Step: 4930 Train Loss: 1.596205\n",
      "Step: 4940 Train Loss: 1.403732\n",
      "Step: 4950 Train Loss: 1.456774\n",
      "Step: 4960 Train Loss: 1.494975\n",
      "Step: 4970 Train Loss: 1.131924\n",
      "Step: 4980 Train Loss: 1.374311\n",
      "Step: 4990 Train Loss: 1.534472\n",
      "Step: 5000 Train Loss: 1.207104\n",
      "==============================================\n",
      "Step: 5000 Validation Loss: 2.161862\n",
      "==============================================\n",
      "Step: 5010 Train Loss: 1.375802\n",
      "Step: 5020 Train Loss: 1.144321\n",
      "Step: 5030 Train Loss: 1.176251\n",
      "Step: 5040 Train Loss: 1.207293\n",
      "Step: 5050 Train Loss: 1.344151\n",
      "Step: 5060 Train Loss: 1.448467\n",
      "Step: 5070 Train Loss: 1.587354\n",
      "Step: 5080 Train Loss: 1.590611\n",
      "Step: 5090 Train Loss: 1.527604\n",
      "Step: 5100 Train Loss: 1.587698\n",
      "Step: 5110 Train Loss: 1.032732\n",
      "Step: 5120 Train Loss: 1.231937\n",
      "Step: 5130 Train Loss: 1.025108\n",
      "Step: 5140 Train Loss: 1.323713\n",
      "Step: 5150 Train Loss: 1.418646\n",
      "Step: 5160 Train Loss: 1.248971\n",
      "Step: 5170 Train Loss: 1.325520\n",
      "Step: 5180 Train Loss: 1.454724\n",
      "Step: 5190 Train Loss: 1.517110\n",
      "Step: 5200 Train Loss: 1.315771\n",
      "==============================================\n",
      "Step: 5200 Validation Loss: 2.227375\n",
      "==============================================\n",
      "Step: 5210 Train Loss: 1.296077\n",
      "Step: 5220 Train Loss: 1.443426\n",
      "Step: 5230 Train Loss: 1.409356\n",
      "Step: 5240 Train Loss: 1.425914\n",
      "Step: 5250 Train Loss: 0.901321\n",
      "Step: 5260 Train Loss: 1.033468\n",
      "Step: 5270 Train Loss: 1.097295\n",
      "Step: 5280 Train Loss: 1.217678\n",
      "Step: 5290 Train Loss: 1.348640\n",
      "Step: 5300 Train Loss: 1.270654\n",
      "Step: 5310 Train Loss: 1.390508\n",
      "Step: 5320 Train Loss: 1.527862\n",
      "Step: 5330 Train Loss: 1.356643\n",
      "Step: 5340 Train Loss: 1.544542\n",
      "Step: 5350 Train Loss: 1.268846\n",
      "Step: 5360 Train Loss: 1.170988\n",
      "Step: 5370 Train Loss: 1.430068\n",
      "Step: 5380 Train Loss: 1.254892\n",
      "Step: 5390 Train Loss: 1.111513\n",
      "Step: 5400 Train Loss: 1.371057\n",
      "==============================================\n",
      "Step: 5400 Validation Loss: 2.549708\n",
      "==============================================\n",
      "Step: 5410 Train Loss: 1.379605\n",
      "Step: 5420 Train Loss: 1.252699\n",
      "Step: 5430 Train Loss: 1.241052\n",
      "Step: 5440 Train Loss: 1.217669\n",
      "Step: 5450 Train Loss: 0.964968\n",
      "Step: 5460 Train Loss: 1.393858\n",
      "Step: 5470 Train Loss: 1.516071\n",
      "Step: 5480 Train Loss: 1.383223\n",
      "Step: 5490 Train Loss: 1.310560\n",
      "Step: 5500 Train Loss: 1.268462\n",
      "Step: 5510 Train Loss: 1.382340\n",
      "Step: 5520 Train Loss: 1.441294\n",
      "Step: 5530 Train Loss: 1.514768\n",
      "Step: 5540 Train Loss: 1.295135\n",
      "Step: 5550 Train Loss: 1.106873\n",
      "Step: 5560 Train Loss: 1.334971\n",
      "Step: 5570 Train Loss: 1.188547\n",
      "Step: 5580 Train Loss: 1.198466\n",
      "Step: 5590 Train Loss: 1.250103\n",
      "Step: 5600 Train Loss: 1.309349\n",
      "==============================================\n",
      "Step: 5600 Validation Loss: 2.497870\n",
      "==============================================\n",
      "Step: 5610 Train Loss: 1.316781\n",
      "Step: 5620 Train Loss: 1.289414\n",
      "Step: 5630 Train Loss: 1.478019\n",
      "Step: 5640 Train Loss: 1.147887\n",
      "Step: 5650 Train Loss: 1.336239\n",
      "Step: 5660 Train Loss: 1.433223\n",
      "Step: 5670 Train Loss: 1.314545\n",
      "Step: 5680 Train Loss: 1.396056\n",
      "Step: 5690 Train Loss: 1.191701\n",
      "Step: 5700 Train Loss: 1.463688\n",
      "Step: 5710 Train Loss: 1.312900\n",
      "Step: 5720 Train Loss: 1.346910\n",
      "Step: 5730 Train Loss: 1.141634\n",
      "Step: 5740 Train Loss: 1.474504\n",
      "Step: 5750 Train Loss: 1.250181\n",
      "Step: 5760 Train Loss: 1.339748\n",
      "Step: 5770 Train Loss: 1.533060\n",
      "Step: 5780 Train Loss: 1.219365\n",
      "Step: 5790 Train Loss: 1.457098\n",
      "Step: 5800 Train Loss: 1.127362\n",
      "==============================================\n",
      "Step: 5800 Validation Loss: 1.946031\n",
      "==============================================\n",
      "Step: 5810 Train Loss: 1.234497\n",
      "Step: 5820 Train Loss: 1.342178\n",
      "Step: 5830 Train Loss: 1.733440\n",
      "Step: 5840 Train Loss: 1.118546\n",
      "Step: 5850 Train Loss: 1.216832\n",
      "Step: 5860 Train Loss: 1.183961\n",
      "Step: 5870 Train Loss: 1.276904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5880 Train Loss: 1.053417\n",
      "Step: 5890 Train Loss: 1.279672\n",
      "Step: 5900 Train Loss: 1.366638\n",
      "Step: 5910 Train Loss: 1.141211\n",
      "Step: 5920 Train Loss: 1.482110\n",
      "Step: 5930 Train Loss: 1.498683\n",
      "Step: 5940 Train Loss: 1.223230\n",
      "Step: 5950 Train Loss: 1.160829\n",
      "Step: 5960 Train Loss: 1.224482\n",
      "Step: 5970 Train Loss: 1.201335\n",
      "Step: 5980 Train Loss: 1.330238\n",
      "Step: 5990 Train Loss: 1.138924\n",
      "Step: 6000 Train Loss: 1.331517\n",
      "==============================================\n",
      "Step: 6000 Validation Loss: 1.958453\n",
      "==============================================\n",
      "Step: 6010 Train Loss: 1.482529\n",
      "Step: 6020 Train Loss: 1.246527\n",
      "Step: 6030 Train Loss: 1.424652\n",
      "Step: 6040 Train Loss: 1.196427\n",
      "Step: 6050 Train Loss: 1.230189\n",
      "Step: 6060 Train Loss: 1.262683\n",
      "Step: 6070 Train Loss: 1.373871\n",
      "Step: 6080 Train Loss: 1.457531\n",
      "Step: 6090 Train Loss: 1.178789\n",
      "Step: 6100 Train Loss: 1.319612\n",
      "Step: 6110 Train Loss: 1.294408\n",
      "Step: 6120 Train Loss: 1.246949\n",
      "Step: 6130 Train Loss: 1.279197\n",
      "Step: 6140 Train Loss: 1.174014\n",
      "Step: 6150 Train Loss: 1.486188\n",
      "Step: 6160 Train Loss: 1.285354\n",
      "Step: 6170 Train Loss: 1.247869\n",
      "Step: 6180 Train Loss: 1.075350\n",
      "Step: 6190 Train Loss: 1.359548\n",
      "Step: 6200 Train Loss: 1.331220\n",
      "==============================================\n",
      "Step: 6200 Validation Loss: 1.678140\n",
      "==============================================\n",
      "Step: 6210 Train Loss: 0.970198\n",
      "Step: 6220 Train Loss: 1.264330\n",
      "Step: 6230 Train Loss: 0.861128\n",
      "Step: 6240 Train Loss: 1.091259\n",
      "Step: 6250 Train Loss: 1.033714\n",
      "Step: 6260 Train Loss: 1.232034\n",
      "Step: 6270 Train Loss: 1.511775\n",
      "Step: 6280 Train Loss: 1.083489\n",
      "Step: 6290 Train Loss: 1.385268\n",
      "Step: 6300 Train Loss: 1.134838\n",
      "Step: 6310 Train Loss: 1.387253\n",
      "Step: 6320 Train Loss: 1.154440\n",
      "Step: 6330 Train Loss: 1.263573\n",
      "Step: 6340 Train Loss: 1.366746\n",
      "Step: 6350 Train Loss: 0.984013\n",
      "Step: 6360 Train Loss: 0.983639\n",
      "Step: 6370 Train Loss: 1.184319\n",
      "Step: 6380 Train Loss: 1.060408\n",
      "Step: 6390 Train Loss: 1.070212\n",
      "Step: 6400 Train Loss: 0.912134\n",
      "==============================================\n",
      "Step: 6400 Validation Loss: 2.880246\n",
      "==============================================\n",
      "Step: 6410 Train Loss: 1.237238\n",
      "Step: 6420 Train Loss: 1.335776\n",
      "Step: 6430 Train Loss: 1.406255\n",
      "Step: 6440 Train Loss: 1.043786\n",
      "Step: 6450 Train Loss: 1.085193\n",
      "Step: 6460 Train Loss: 1.269499\n",
      "Step: 6470 Train Loss: 1.109808\n",
      "Step: 6480 Train Loss: 1.283835\n",
      "Step: 6490 Train Loss: 1.064783\n",
      "Step: 6500 Train Loss: 1.107514\n",
      "Step: 6510 Train Loss: 1.504090\n",
      "Step: 6520 Train Loss: 1.217544\n",
      "Step: 6530 Train Loss: 1.067342\n",
      "Step: 6540 Train Loss: 1.502721\n",
      "Step: 6550 Train Loss: 1.209290\n",
      "Step: 6560 Train Loss: 1.400199\n",
      "Step: 6570 Train Loss: 1.395904\n",
      "Step: 6580 Train Loss: 1.356212\n",
      "Step: 6590 Train Loss: 1.268085\n",
      "Step: 6600 Train Loss: 1.272941\n",
      "==============================================\n",
      "Step: 6600 Validation Loss: 2.413333\n",
      "==============================================\n",
      "Step: 6610 Train Loss: 1.015286\n",
      "Step: 6620 Train Loss: 1.367916\n",
      "Step: 6630 Train Loss: 1.159743\n",
      "Step: 6640 Train Loss: 1.064123\n",
      "Step: 6650 Train Loss: 1.129104\n",
      "Step: 6660 Train Loss: 1.236714\n",
      "Step: 6670 Train Loss: 1.382984\n",
      "Step: 6680 Train Loss: 1.180861\n",
      "Step: 6690 Train Loss: 1.280713\n",
      "Step: 6700 Train Loss: 1.131363\n",
      "Step: 6710 Train Loss: 1.259221\n",
      "Step: 6720 Train Loss: 1.063277\n",
      "Step: 6730 Train Loss: 1.561694\n",
      "Step: 6740 Train Loss: 1.353690\n",
      "Step: 6750 Train Loss: 1.183495\n",
      "Step: 6760 Train Loss: 1.253127\n",
      "Step: 6770 Train Loss: 1.322089\n",
      "Step: 6780 Train Loss: 1.209373\n",
      "Step: 6790 Train Loss: 1.176340\n",
      "Step: 6800 Train Loss: 1.211077\n",
      "==============================================\n",
      "Step: 6800 Validation Loss: 2.064561\n",
      "==============================================\n",
      "Step: 6810 Train Loss: 1.083766\n",
      "Step: 6820 Train Loss: 1.366344\n",
      "Step: 6830 Train Loss: 1.318698\n",
      "Step: 6840 Train Loss: 1.124920\n",
      "Step: 6850 Train Loss: 1.058310\n",
      "Step: 6860 Train Loss: 1.343045\n",
      "Step: 6870 Train Loss: 1.104549\n",
      "Step: 6880 Train Loss: 1.384421\n",
      "Step: 6890 Train Loss: 1.331591\n",
      "Step: 6900 Train Loss: 1.327123\n",
      "Step: 6910 Train Loss: 1.116126\n",
      "Step: 6920 Train Loss: 1.229664\n",
      "Step: 6930 Train Loss: 1.297536\n",
      "Step: 6940 Train Loss: 1.393615\n",
      "Step: 6950 Train Loss: 1.104043\n",
      "Step: 6960 Train Loss: 0.967096\n",
      "Step: 6970 Train Loss: 1.150428\n",
      "Step: 6980 Train Loss: 1.368837\n",
      "Step: 6990 Train Loss: 1.214756\n",
      "Step: 7000 Train Loss: 1.103090\n",
      "==============================================\n",
      "Step: 7000 Validation Loss: 1.457421\n",
      "==============================================\n",
      "Step: 7010 Train Loss: 1.167691\n",
      "Step: 7020 Train Loss: 1.423750\n",
      "Step: 7030 Train Loss: 1.572058\n",
      "Step: 7040 Train Loss: 1.107727\n",
      "Step: 7050 Train Loss: 1.351490\n",
      "Step: 7060 Train Loss: 1.520155\n",
      "Step: 7070 Train Loss: 1.235716\n",
      "Step: 7080 Train Loss: 1.130544\n",
      "Step: 7090 Train Loss: 1.064226\n",
      "Step: 7100 Train Loss: 1.029880\n",
      "Step: 7110 Train Loss: 1.182337\n",
      "Step: 7120 Train Loss: 1.371432\n",
      "Step: 7130 Train Loss: 1.070223\n",
      "Step: 7140 Train Loss: 1.147898\n",
      "Step: 7150 Train Loss: 1.403907\n",
      "Step: 7160 Train Loss: 1.265149\n",
      "Step: 7170 Train Loss: 1.008787\n",
      "Step: 7180 Train Loss: 1.087441\n",
      "Step: 7190 Train Loss: 1.095728\n",
      "Step: 7200 Train Loss: 1.404684\n",
      "==============================================\n",
      "Step: 7200 Validation Loss: 1.642977\n",
      "==============================================\n",
      "Step: 7210 Train Loss: 1.486263\n",
      "Step: 7220 Train Loss: 1.071602\n",
      "Step: 7230 Train Loss: 1.057815\n",
      "Step: 7240 Train Loss: 1.181310\n",
      "Step: 7250 Train Loss: 1.219444\n",
      "Step: 7260 Train Loss: 1.006556\n",
      "Step: 7270 Train Loss: 1.349654\n",
      "Step: 7280 Train Loss: 1.302803\n",
      "Step: 7290 Train Loss: 0.996919\n",
      "Step: 7300 Train Loss: 1.181757\n",
      "Step: 7310 Train Loss: 1.180862\n",
      "Step: 7320 Train Loss: 1.347086\n",
      "Step: 7330 Train Loss: 1.101591\n",
      "Step: 7340 Train Loss: 1.235117\n",
      "Step: 7350 Train Loss: 1.078786\n",
      "Step: 7360 Train Loss: 1.352904\n",
      "Step: 7370 Train Loss: 1.440164\n",
      "Step: 7380 Train Loss: 1.275505\n",
      "Step: 7390 Train Loss: 1.258061\n",
      "Step: 7400 Train Loss: 1.079371\n",
      "==============================================\n",
      "Step: 7400 Validation Loss: 1.357844\n",
      "==============================================\n",
      "Step: 7410 Train Loss: 0.906418\n",
      "Step: 7420 Train Loss: 1.201221\n",
      "Step: 7430 Train Loss: 1.280541\n",
      "Step: 7440 Train Loss: 1.124158\n",
      "Step: 7450 Train Loss: 1.163858\n",
      "Step: 7460 Train Loss: 1.125785\n",
      "Step: 7470 Train Loss: 1.195413\n",
      "Step: 7480 Train Loss: 1.150159\n",
      "Step: 7490 Train Loss: 1.136701\n",
      "Step: 7500 Train Loss: 1.200517\n",
      "Step: 7510 Train Loss: 1.148775\n",
      "Step: 7520 Train Loss: 1.268548\n",
      "Step: 7530 Train Loss: 1.259398\n",
      "Step: 7540 Train Loss: 1.059577\n",
      "Step: 7550 Train Loss: 1.031803\n",
      "Step: 7560 Train Loss: 1.139890\n",
      "Step: 7570 Train Loss: 1.252590\n",
      "Step: 7580 Train Loss: 1.295286\n",
      "Step: 7590 Train Loss: 1.168833\n",
      "Step: 7600 Train Loss: 1.376578\n",
      "==============================================\n",
      "Step: 7600 Validation Loss: 2.248644\n",
      "==============================================\n",
      "Step: 7610 Train Loss: 0.843411\n",
      "Step: 7620 Train Loss: 1.272324\n",
      "Step: 7630 Train Loss: 1.186987\n",
      "Step: 7640 Train Loss: 1.039514\n",
      "Step: 7650 Train Loss: 1.514208\n",
      "Step: 7660 Train Loss: 1.025229\n",
      "Step: 7670 Train Loss: 1.208803\n",
      "Step: 7680 Train Loss: 1.231880\n",
      "Step: 7690 Train Loss: 1.078865\n",
      "Step: 7700 Train Loss: 1.620823\n",
      "Step: 7710 Train Loss: 1.234720\n",
      "Step: 7720 Train Loss: 1.162253\n",
      "Step: 7730 Train Loss: 1.334248\n",
      "Step: 7740 Train Loss: 1.009313\n",
      "Step: 7750 Train Loss: 0.843972\n",
      "Step: 7760 Train Loss: 1.244143\n",
      "Step: 7770 Train Loss: 1.289755\n",
      "Step: 7780 Train Loss: 1.300660\n",
      "Step: 7790 Train Loss: 1.193748\n",
      "Step: 7800 Train Loss: 0.986146\n",
      "==============================================\n",
      "Step: 7800 Validation Loss: 2.105526\n",
      "==============================================\n",
      "Step: 7810 Train Loss: 1.155213\n",
      "Step: 7820 Train Loss: 1.410134\n",
      "Step: 7830 Train Loss: 1.326450\n",
      "Step: 7840 Train Loss: 1.070038\n",
      "Step: 7850 Train Loss: 1.183428\n",
      "Step: 7860 Train Loss: 1.509279\n",
      "Step: 7870 Train Loss: 1.129759\n",
      "Step: 7880 Train Loss: 1.112460\n",
      "Step: 7890 Train Loss: 1.344155\n",
      "Step: 7900 Train Loss: 1.134101\n",
      "Step: 7910 Train Loss: 1.330026\n",
      "Step: 7920 Train Loss: 1.144481\n",
      "Step: 7930 Train Loss: 1.023387\n",
      "Step: 7940 Train Loss: 1.305202\n",
      "Step: 7950 Train Loss: 1.011714\n",
      "Step: 7960 Train Loss: 1.397651\n",
      "Step: 7970 Train Loss: 0.967635\n",
      "Step: 7980 Train Loss: 1.088196\n",
      "Step: 7990 Train Loss: 1.110944\n",
      "Step: 8000 Train Loss: 1.027413\n",
      "==============================================\n",
      "Step: 8000 Validation Loss: 2.226005\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8010 Train Loss: 1.094004\n",
      "Step: 8020 Train Loss: 1.210347\n",
      "Step: 8030 Train Loss: 1.283330\n",
      "Step: 8040 Train Loss: 1.266639\n",
      "Step: 8050 Train Loss: 1.001756\n",
      "Step: 8060 Train Loss: 1.372735\n",
      "Step: 8070 Train Loss: 1.045686\n",
      "Step: 8080 Train Loss: 1.063534\n",
      "Step: 8090 Train Loss: 1.149076\n",
      "Step: 8100 Train Loss: 1.431229\n",
      "Step: 8110 Train Loss: 1.196322\n",
      "Step: 8120 Train Loss: 1.003397\n",
      "Step: 8130 Train Loss: 0.989463\n",
      "Step: 8140 Train Loss: 1.200534\n",
      "Step: 8150 Train Loss: 1.157094\n",
      "Step: 8160 Train Loss: 1.156766\n",
      "Step: 8170 Train Loss: 1.283719\n",
      "Step: 8180 Train Loss: 1.109174\n",
      "Step: 8190 Train Loss: 1.261038\n",
      "Step: 8200 Train Loss: 1.011216\n",
      "==============================================\n",
      "Step: 8200 Validation Loss: 2.642907\n",
      "==============================================\n",
      "Step: 8210 Train Loss: 1.193456\n",
      "Step: 8220 Train Loss: 1.188620\n",
      "Step: 8230 Train Loss: 1.007746\n",
      "Step: 8240 Train Loss: 1.123623\n",
      "Step: 8250 Train Loss: 0.905853\n",
      "Step: 8260 Train Loss: 1.222895\n",
      "Step: 8270 Train Loss: 1.012076\n",
      "Step: 8280 Train Loss: 1.097430\n",
      "Step: 8290 Train Loss: 1.075557\n",
      "Step: 8300 Train Loss: 1.386413\n",
      "Step: 8310 Train Loss: 1.295162\n",
      "Step: 8320 Train Loss: 1.063716\n",
      "Step: 8330 Train Loss: 1.209494\n",
      "Step: 8340 Train Loss: 1.184170\n",
      "Step: 8350 Train Loss: 0.902057\n",
      "Step: 8360 Train Loss: 0.881580\n",
      "Step: 8370 Train Loss: 1.239631\n",
      "Step: 8380 Train Loss: 1.327837\n",
      "Step: 8390 Train Loss: 1.058373\n",
      "Step: 8400 Train Loss: 1.098820\n",
      "==============================================\n",
      "Step: 8400 Validation Loss: 2.425526\n",
      "==============================================\n",
      "Step: 8410 Train Loss: 1.330710\n",
      "Step: 8420 Train Loss: 1.228534\n",
      "Step: 8430 Train Loss: 1.117558\n",
      "Step: 8440 Train Loss: 1.129131\n",
      "Step: 8450 Train Loss: 1.171017\n",
      "Step: 8460 Train Loss: 1.027281\n",
      "Step: 8470 Train Loss: 1.176828\n",
      "Step: 8480 Train Loss: 1.234499\n",
      "Step: 8490 Train Loss: 1.147518\n",
      "Step: 8500 Train Loss: 1.018659\n",
      "Step: 8510 Train Loss: 1.379177\n",
      "Step: 8520 Train Loss: 1.190148\n",
      "Step: 8530 Train Loss: 1.194429\n",
      "Step: 8540 Train Loss: 1.297996\n",
      "Step: 8550 Train Loss: 1.174150\n",
      "Step: 8560 Train Loss: 0.974584\n",
      "Step: 8570 Train Loss: 1.356189\n",
      "Step: 8580 Train Loss: 1.126563\n",
      "Step: 8590 Train Loss: 1.120118\n",
      "Step: 8600 Train Loss: 1.175588\n",
      "==============================================\n",
      "Step: 8600 Validation Loss: 2.481814\n",
      "==============================================\n",
      "Step: 8610 Train Loss: 0.922268\n",
      "Step: 8620 Train Loss: 1.112041\n",
      "Step: 8630 Train Loss: 1.238245\n",
      "Step: 8640 Train Loss: 1.111820\n",
      "Step: 8650 Train Loss: 1.061956\n",
      "Step: 8660 Train Loss: 1.104277\n",
      "Step: 8670 Train Loss: 0.973601\n",
      "Step: 8680 Train Loss: 1.092298\n",
      "Step: 8690 Train Loss: 1.079947\n",
      "Step: 8700 Train Loss: 1.215509\n",
      "Step: 8710 Train Loss: 1.108394\n",
      "Step: 8720 Train Loss: 0.902576\n",
      "Step: 8730 Train Loss: 1.028887\n",
      "Step: 8740 Train Loss: 1.013984\n",
      "Step: 8750 Train Loss: 1.066515\n",
      "Step: 8760 Train Loss: 1.129230\n",
      "Step: 8770 Train Loss: 1.335499\n",
      "Step: 8780 Train Loss: 0.987481\n",
      "Step: 8790 Train Loss: 1.110361\n",
      "Step: 8800 Train Loss: 1.382459\n",
      "==============================================\n",
      "Step: 8800 Validation Loss: 2.027281\n",
      "==============================================\n",
      "Step: 8810 Train Loss: 0.934661\n",
      "Step: 8820 Train Loss: 1.261705\n",
      "Step: 8830 Train Loss: 1.094585\n",
      "Step: 8840 Train Loss: 1.200639\n",
      "Step: 8850 Train Loss: 0.876392\n",
      "Step: 8860 Train Loss: 1.112739\n",
      "Step: 8870 Train Loss: 0.850652\n",
      "Step: 8880 Train Loss: 1.233196\n",
      "Step: 8890 Train Loss: 1.118621\n",
      "Step: 8900 Train Loss: 0.939686\n",
      "Step: 8910 Train Loss: 1.300932\n",
      "Step: 8920 Train Loss: 0.964495\n",
      "Step: 8930 Train Loss: 1.027453\n",
      "Step: 8940 Train Loss: 1.185438\n",
      "Step: 8950 Train Loss: 1.110122\n",
      "Step: 8960 Train Loss: 1.226378\n",
      "Step: 8970 Train Loss: 1.009237\n",
      "Step: 8980 Train Loss: 0.991672\n",
      "Step: 8990 Train Loss: 1.239522\n",
      "Step: 9000 Train Loss: 1.234050\n",
      "==============================================\n",
      "Step: 9000 Validation Loss: 2.116559\n",
      "==============================================\n",
      "Step: 9010 Train Loss: 0.990428\n",
      "Step: 9020 Train Loss: 1.371370\n",
      "Step: 9030 Train Loss: 1.101454\n",
      "Step: 9040 Train Loss: 0.996837\n",
      "Step: 9050 Train Loss: 1.245253\n",
      "Step: 9060 Train Loss: 0.925673\n",
      "Step: 9070 Train Loss: 0.990341\n",
      "Step: 9080 Train Loss: 1.244441\n",
      "Step: 9090 Train Loss: 1.165595\n",
      "Step: 9100 Train Loss: 1.044318\n",
      "Step: 9110 Train Loss: 1.135949\n",
      "Step: 9120 Train Loss: 1.155728\n",
      "Step: 9130 Train Loss: 0.864648\n",
      "Step: 9140 Train Loss: 0.967680\n",
      "Step: 9150 Train Loss: 1.337947\n",
      "Step: 9160 Train Loss: 0.869541\n",
      "Step: 9170 Train Loss: 1.062016\n",
      "Step: 9180 Train Loss: 0.973265\n",
      "Step: 9190 Train Loss: 0.829949\n",
      "Step: 9200 Train Loss: 1.168855\n",
      "==============================================\n",
      "Step: 9200 Validation Loss: 2.036535\n",
      "==============================================\n",
      "Step: 9210 Train Loss: 1.037510\n",
      "Step: 9220 Train Loss: 1.137936\n",
      "Step: 9230 Train Loss: 0.867896\n",
      "Step: 9240 Train Loss: 1.084012\n",
      "Step: 9250 Train Loss: 1.123995\n",
      "Step: 9260 Train Loss: 0.955882\n",
      "Step: 9270 Train Loss: 1.070701\n",
      "Step: 9280 Train Loss: 0.929708\n",
      "Step: 9290 Train Loss: 1.265043\n",
      "Step: 9300 Train Loss: 1.181993\n",
      "Step: 9310 Train Loss: 1.150679\n",
      "Step: 9320 Train Loss: 1.148631\n",
      "Step: 9330 Train Loss: 1.474014\n",
      "Step: 9340 Train Loss: 1.000880\n",
      "Step: 9350 Train Loss: 1.078537\n",
      "Step: 9360 Train Loss: 1.107196\n",
      "Step: 9370 Train Loss: 1.087556\n",
      "Step: 9380 Train Loss: 1.152986\n",
      "Step: 9390 Train Loss: 0.957699\n",
      "Step: 9400 Train Loss: 1.081540\n",
      "==============================================\n",
      "Step: 9400 Validation Loss: 2.536269\n",
      "==============================================\n",
      "Step: 9410 Train Loss: 1.131874\n",
      "Step: 9420 Train Loss: 1.426747\n",
      "Step: 9430 Train Loss: 0.872664\n",
      "Step: 9440 Train Loss: 1.258262\n",
      "Step: 9450 Train Loss: 1.045721\n",
      "Step: 9460 Train Loss: 1.050495\n",
      "Step: 9470 Train Loss: 1.275938\n",
      "Step: 9480 Train Loss: 1.058401\n",
      "Step: 9490 Train Loss: 1.058563\n",
      "Step: 9500 Train Loss: 1.271680\n",
      "Step: 9510 Train Loss: 1.272879\n",
      "Step: 9520 Train Loss: 1.183183\n",
      "Step: 9530 Train Loss: 1.032146\n",
      "Step: 9540 Train Loss: 1.210950\n",
      "Step: 9550 Train Loss: 1.020144\n",
      "Step: 9560 Train Loss: 1.368222\n",
      "Step: 9570 Train Loss: 0.944819\n",
      "Step: 9580 Train Loss: 1.104169\n",
      "Step: 9590 Train Loss: 0.972302\n",
      "Step: 9600 Train Loss: 1.016069\n",
      "==============================================\n",
      "Step: 9600 Validation Loss: 1.767300\n",
      "==============================================\n",
      "Step: 9610 Train Loss: 1.136733\n",
      "Step: 9620 Train Loss: 1.094995\n",
      "Step: 9630 Train Loss: 0.922051\n",
      "Step: 9640 Train Loss: 1.031586\n",
      "Step: 9650 Train Loss: 1.223422\n",
      "Step: 9660 Train Loss: 0.998347\n",
      "Step: 9670 Train Loss: 1.185902\n",
      "Step: 9680 Train Loss: 0.909783\n",
      "Step: 9690 Train Loss: 1.066869\n",
      "Step: 9700 Train Loss: 0.934234\n",
      "Step: 9710 Train Loss: 0.986702\n",
      "Step: 9720 Train Loss: 0.995748\n",
      "Step: 9730 Train Loss: 0.827522\n",
      "Step: 9740 Train Loss: 0.963240\n",
      "Step: 9750 Train Loss: 1.130574\n",
      "Step: 9760 Train Loss: 1.007940\n",
      "Step: 9770 Train Loss: 0.910754\n",
      "Step: 9780 Train Loss: 1.261703\n",
      "Step: 9790 Train Loss: 1.183161\n",
      "Step: 9800 Train Loss: 1.051530\n",
      "==============================================\n",
      "Step: 9800 Validation Loss: 2.261172\n",
      "==============================================\n",
      "Step: 9810 Train Loss: 1.223748\n",
      "Step: 9820 Train Loss: 1.063875\n",
      "Step: 9830 Train Loss: 1.031944\n",
      "Step: 9840 Train Loss: 1.169223\n",
      "Step: 9850 Train Loss: 1.154570\n",
      "Step: 9860 Train Loss: 1.042276\n",
      "Step: 9870 Train Loss: 1.016749\n",
      "Step: 9880 Train Loss: 0.959289\n",
      "Step: 9890 Train Loss: 1.122703\n",
      "Step: 9900 Train Loss: 1.112815\n",
      "Step: 9910 Train Loss: 1.252599\n",
      "Step: 9920 Train Loss: 1.108009\n",
      "Step: 9930 Train Loss: 0.927087\n",
      "Step: 9940 Train Loss: 1.096295\n",
      "Step: 9950 Train Loss: 1.203120\n",
      "Step: 9960 Train Loss: 0.988656\n",
      "Step: 9970 Train Loss: 1.086280\n",
      "Step: 9980 Train Loss: 1.279014\n",
      "Step: 9990 Train Loss: 0.994368\n",
      "Step: 10000 Train Loss: 1.025391\n",
      "==============================================\n",
      "Step: 10000 Validation Loss: 2.118410\n",
      "==============================================\n",
      "Step: 10010 Train Loss: 1.150652\n",
      "Step: 10020 Train Loss: 0.958933\n",
      "Step: 10030 Train Loss: 1.126252\n",
      "Step: 10040 Train Loss: 0.927211\n",
      "Step: 10050 Train Loss: 1.260410\n",
      "Step: 10060 Train Loss: 1.071453\n",
      "Step: 10070 Train Loss: 1.150984\n",
      "Step: 10080 Train Loss: 0.981995\n",
      "Step: 10090 Train Loss: 0.928495\n",
      "Step: 10100 Train Loss: 1.095110\n",
      "Step: 10110 Train Loss: 1.180755\n",
      "Step: 10120 Train Loss: 1.290790\n",
      "Step: 10130 Train Loss: 1.261353\n",
      "Step: 10140 Train Loss: 0.747033\n",
      "Step: 10150 Train Loss: 1.167953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10160 Train Loss: 1.329881\n",
      "Step: 10170 Train Loss: 0.861469\n",
      "Step: 10180 Train Loss: 1.252404\n",
      "Step: 10190 Train Loss: 0.932264\n",
      "Step: 10200 Train Loss: 0.973654\n",
      "==============================================\n",
      "Step: 10200 Validation Loss: 2.625398\n",
      "==============================================\n",
      "Step: 10210 Train Loss: 1.108951\n",
      "Step: 10220 Train Loss: 1.033662\n",
      "Step: 10230 Train Loss: 1.001208\n",
      "Step: 10240 Train Loss: 0.825192\n",
      "Step: 10250 Train Loss: 1.110257\n",
      "Step: 10260 Train Loss: 1.115697\n",
      "Step: 10270 Train Loss: 1.129456\n",
      "Step: 10280 Train Loss: 0.845266\n",
      "Step: 10290 Train Loss: 1.088261\n",
      "Step: 10300 Train Loss: 1.135433\n",
      "Step: 10310 Train Loss: 1.154914\n",
      "Step: 10320 Train Loss: 1.012836\n",
      "Step: 10330 Train Loss: 0.883620\n",
      "Step: 10340 Train Loss: 0.977711\n",
      "Step: 10350 Train Loss: 0.918664\n",
      "Step: 10360 Train Loss: 1.057654\n",
      "Step: 10370 Train Loss: 0.797629\n",
      "Step: 10380 Train Loss: 0.966382\n",
      "Step: 10390 Train Loss: 1.005314\n",
      "Step: 10400 Train Loss: 1.231537\n",
      "==============================================\n",
      "Step: 10400 Validation Loss: 2.299562\n",
      "==============================================\n",
      "Step: 10410 Train Loss: 0.832516\n",
      "Step: 10420 Train Loss: 0.786392\n",
      "Step: 10430 Train Loss: 1.016406\n",
      "Step: 10440 Train Loss: 0.786613\n",
      "Step: 10450 Train Loss: 0.762399\n",
      "Step: 10460 Train Loss: 0.990438\n",
      "Step: 10470 Train Loss: 1.103617\n",
      "Step: 10480 Train Loss: 0.976756\n",
      "Step: 10490 Train Loss: 0.881653\n",
      "Step: 10500 Train Loss: 1.148508\n",
      "Step: 10510 Train Loss: 1.023390\n",
      "Step: 10520 Train Loss: 0.700069\n",
      "Step: 10530 Train Loss: 0.893527\n",
      "Step: 10540 Train Loss: 1.085097\n",
      "Step: 10550 Train Loss: 0.903826\n",
      "Step: 10560 Train Loss: 1.014309\n",
      "Step: 10570 Train Loss: 0.674197\n",
      "Step: 10580 Train Loss: 0.810772\n",
      "Step: 10590 Train Loss: 0.976913\n",
      "Step: 10600 Train Loss: 0.954590\n",
      "==============================================\n",
      "Step: 10600 Validation Loss: 2.478005\n",
      "==============================================\n",
      "Step: 10610 Train Loss: 1.004191\n",
      "Step: 10620 Train Loss: 0.861753\n",
      "Step: 10630 Train Loss: 0.938691\n",
      "Step: 10640 Train Loss: 0.858550\n",
      "Step: 10650 Train Loss: 0.902162\n",
      "Step: 10660 Train Loss: 0.909439\n",
      "Step: 10670 Train Loss: 0.887667\n",
      "Step: 10680 Train Loss: 1.247355\n",
      "Step: 10690 Train Loss: 1.000078\n",
      "Step: 10700 Train Loss: 0.835026\n",
      "Step: 10710 Train Loss: 0.985176\n",
      "Step: 10720 Train Loss: 0.943908\n",
      "Step: 10730 Train Loss: 0.989059\n",
      "Step: 10740 Train Loss: 0.929567\n",
      "Step: 10750 Train Loss: 0.979463\n",
      "Step: 10760 Train Loss: 0.895570\n",
      "Step: 10770 Train Loss: 0.846998\n",
      "Step: 10780 Train Loss: 0.725780\n",
      "Step: 10790 Train Loss: 1.049269\n",
      "Step: 10800 Train Loss: 1.009522\n",
      "==============================================\n",
      "Step: 10800 Validation Loss: 1.983346\n",
      "==============================================\n",
      "Step: 10810 Train Loss: 0.817134\n",
      "Step: 10820 Train Loss: 1.001798\n",
      "Step: 10830 Train Loss: 0.840565\n",
      "Step: 10840 Train Loss: 0.661389\n",
      "Step: 10850 Train Loss: 1.111356\n",
      "Step: 10860 Train Loss: 1.033955\n",
      "Step: 10870 Train Loss: 0.932661\n",
      "Step: 10880 Train Loss: 1.136099\n",
      "Step: 10890 Train Loss: 0.989538\n",
      "Step: 10900 Train Loss: 0.934038\n",
      "Step: 10910 Train Loss: 1.017215\n",
      "Step: 10920 Train Loss: 1.019623\n",
      "Step: 10930 Train Loss: 0.857824\n",
      "Step: 10940 Train Loss: 1.077585\n",
      "Step: 10950 Train Loss: 0.947999\n",
      "Step: 10960 Train Loss: 0.711733\n",
      "Step: 10970 Train Loss: 0.848385\n",
      "Step: 10980 Train Loss: 1.053645\n",
      "Step: 10990 Train Loss: 0.799701\n",
      "Step: 11000 Train Loss: 1.024904\n",
      "==============================================\n",
      "Step: 11000 Validation Loss: 2.610940\n",
      "==============================================\n",
      "Step: 11010 Train Loss: 1.029325\n",
      "Step: 11020 Train Loss: 0.899312\n",
      "Step: 11030 Train Loss: 1.327324\n",
      "Step: 11040 Train Loss: 0.839941\n",
      "Step: 11050 Train Loss: 0.963692\n",
      "Step: 11060 Train Loss: 0.802054\n",
      "Step: 11070 Train Loss: 0.885469\n",
      "Step: 11080 Train Loss: 0.925317\n",
      "Step: 11090 Train Loss: 0.989077\n",
      "Step: 11100 Train Loss: 0.969918\n",
      "Step: 11110 Train Loss: 0.988311\n",
      "Step: 11120 Train Loss: 1.012500\n",
      "Step: 11130 Train Loss: 0.872109\n",
      "Step: 11140 Train Loss: 1.055972\n",
      "Step: 11150 Train Loss: 0.796982\n",
      "Step: 11160 Train Loss: 0.744861\n",
      "Step: 11170 Train Loss: 0.875539\n",
      "Step: 11180 Train Loss: 1.047582\n",
      "Step: 11190 Train Loss: 1.024611\n",
      "Step: 11200 Train Loss: 0.967594\n",
      "==============================================\n",
      "Step: 11200 Validation Loss: 1.973109\n",
      "==============================================\n",
      "Step: 11210 Train Loss: 0.790547\n",
      "Step: 11220 Train Loss: 0.853473\n",
      "Step: 11230 Train Loss: 0.803370\n",
      "Step: 11240 Train Loss: 0.952096\n",
      "Step: 11250 Train Loss: 0.943937\n",
      "Step: 11260 Train Loss: 0.783962\n",
      "Step: 11270 Train Loss: 1.058305\n",
      "Step: 11280 Train Loss: 0.837399\n",
      "Step: 11290 Train Loss: 0.927805\n",
      "Step: 11300 Train Loss: 0.790341\n",
      "Step: 11310 Train Loss: 0.958226\n",
      "Step: 11320 Train Loss: 0.937072\n",
      "Step: 11330 Train Loss: 0.720761\n",
      "Step: 11340 Train Loss: 0.926370\n",
      "Step: 11350 Train Loss: 1.002537\n",
      "Step: 11360 Train Loss: 1.020417\n",
      "Step: 11370 Train Loss: 0.925257\n",
      "Step: 11380 Train Loss: 1.029097\n",
      "Step: 11390 Train Loss: 0.693049\n",
      "Step: 11400 Train Loss: 0.806170\n",
      "==============================================\n",
      "Step: 11400 Validation Loss: 2.579797\n",
      "==============================================\n",
      "Step: 11410 Train Loss: 0.635842\n",
      "Step: 11420 Train Loss: 0.981217\n",
      "Step: 11430 Train Loss: 0.748051\n",
      "Step: 11440 Train Loss: 1.019912\n",
      "Step: 11450 Train Loss: 0.860858\n",
      "Step: 11460 Train Loss: 0.798414\n",
      "Step: 11470 Train Loss: 1.036835\n",
      "Step: 11480 Train Loss: 0.901826\n",
      "Step: 11490 Train Loss: 0.849254\n",
      "Step: 11500 Train Loss: 0.963905\n",
      "Step: 11510 Train Loss: 0.979322\n",
      "Step: 11520 Train Loss: 0.970395\n",
      "Step: 11530 Train Loss: 1.065896\n",
      "Step: 11540 Train Loss: 0.681462\n",
      "Step: 11550 Train Loss: 0.922070\n",
      "Step: 11560 Train Loss: 0.986758\n",
      "Step: 11570 Train Loss: 1.103290\n",
      "Step: 11580 Train Loss: 0.958048\n",
      "Step: 11590 Train Loss: 1.068397\n",
      "Step: 11600 Train Loss: 0.748762\n",
      "==============================================\n",
      "Step: 11600 Validation Loss: 1.886900\n",
      "==============================================\n",
      "Step: 11610 Train Loss: 0.736209\n",
      "Step: 11620 Train Loss: 0.917884\n",
      "Step: 11630 Train Loss: 0.977456\n",
      "Step: 11640 Train Loss: 1.015893\n",
      "Step: 11650 Train Loss: 0.772702\n",
      "Step: 11660 Train Loss: 0.870147\n",
      "Step: 11670 Train Loss: 1.010702\n",
      "Step: 11680 Train Loss: 0.855107\n",
      "Step: 11690 Train Loss: 0.984395\n",
      "Step: 11700 Train Loss: 0.942167\n",
      "Step: 11710 Train Loss: 0.946762\n",
      "Step: 11720 Train Loss: 0.773884\n",
      "Step: 11730 Train Loss: 1.061329\n",
      "Step: 11740 Train Loss: 0.854303\n",
      "Step: 11750 Train Loss: 1.076708\n",
      "Step: 11760 Train Loss: 0.958488\n",
      "Step: 11770 Train Loss: 1.238612\n",
      "Step: 11780 Train Loss: 0.856247\n",
      "Step: 11790 Train Loss: 0.976629\n",
      "Step: 11800 Train Loss: 0.884781\n",
      "==============================================\n",
      "Step: 11800 Validation Loss: 1.494466\n",
      "==============================================\n",
      "Step: 11810 Train Loss: 1.047822\n",
      "Step: 11820 Train Loss: 0.726991\n",
      "Step: 11830 Train Loss: 0.828346\n",
      "Step: 11840 Train Loss: 0.824200\n",
      "Step: 11850 Train Loss: 0.762958\n",
      "Step: 11860 Train Loss: 0.815147\n",
      "Step: 11870 Train Loss: 0.880813\n",
      "Step: 11880 Train Loss: 0.844504\n",
      "Step: 11890 Train Loss: 0.807833\n",
      "Step: 11900 Train Loss: 0.590198\n",
      "Step: 11910 Train Loss: 0.764876\n",
      "Step: 11920 Train Loss: 1.026387\n",
      "Step: 11930 Train Loss: 1.055759\n",
      "Step: 11940 Train Loss: 0.906473\n",
      "Step: 11950 Train Loss: 0.852660\n",
      "Step: 11960 Train Loss: 0.748238\n",
      "Step: 11970 Train Loss: 0.951707\n",
      "Step: 11980 Train Loss: 0.752033\n",
      "Step: 11990 Train Loss: 0.763858\n",
      "Step: 12000 Train Loss: 0.805719\n",
      "==============================================\n",
      "Step: 12000 Validation Loss: 2.335813\n",
      "==============================================\n",
      "Step: 12010 Train Loss: 0.865155\n",
      "Step: 12020 Train Loss: 0.691814\n",
      "Step: 12030 Train Loss: 0.861283\n",
      "Step: 12040 Train Loss: 0.828006\n",
      "Step: 12050 Train Loss: 0.941471\n",
      "Step: 12060 Train Loss: 0.853559\n",
      "Step: 12070 Train Loss: 0.981380\n",
      "Step: 12080 Train Loss: 0.787177\n",
      "Step: 12090 Train Loss: 0.742506\n",
      "Step: 12100 Train Loss: 0.831423\n",
      "Step: 12110 Train Loss: 0.868316\n",
      "Step: 12120 Train Loss: 0.828779\n",
      "Step: 12130 Train Loss: 0.890900\n",
      "Step: 12140 Train Loss: 0.807865\n",
      "Step: 12150 Train Loss: 0.889629\n",
      "Step: 12160 Train Loss: 0.817667\n",
      "Step: 12170 Train Loss: 0.891850\n",
      "Step: 12180 Train Loss: 0.659831\n",
      "Step: 12190 Train Loss: 0.861355\n",
      "Step: 12200 Train Loss: 0.830847\n",
      "==============================================\n",
      "Step: 12200 Validation Loss: 2.791498\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12210 Train Loss: 0.905944\n",
      "Step: 12220 Train Loss: 0.850331\n",
      "Step: 12230 Train Loss: 1.067334\n",
      "Step: 12240 Train Loss: 0.958705\n",
      "Step: 12250 Train Loss: 0.984660\n",
      "Step: 12260 Train Loss: 0.868434\n",
      "Step: 12270 Train Loss: 0.884067\n",
      "Step: 12280 Train Loss: 0.762732\n",
      "Step: 12290 Train Loss: 0.836038\n",
      "Step: 12300 Train Loss: 0.750202\n",
      "Step: 12310 Train Loss: 0.946119\n",
      "Step: 12320 Train Loss: 0.942075\n",
      "Step: 12330 Train Loss: 0.805907\n",
      "Step: 12340 Train Loss: 0.963952\n",
      "Step: 12350 Train Loss: 1.111670\n",
      "Step: 12360 Train Loss: 0.790703\n",
      "Step: 12370 Train Loss: 0.888116\n",
      "Step: 12380 Train Loss: 1.026627\n",
      "Step: 12390 Train Loss: 0.846633\n",
      "Step: 12400 Train Loss: 0.915605\n",
      "==============================================\n",
      "Step: 12400 Validation Loss: 2.205266\n",
      "==============================================\n",
      "Step: 12410 Train Loss: 0.898657\n",
      "Step: 12420 Train Loss: 0.871855\n",
      "Step: 12430 Train Loss: 0.728906\n",
      "Step: 12440 Train Loss: 0.741083\n",
      "Step: 12450 Train Loss: 0.961321\n",
      "Step: 12460 Train Loss: 0.830610\n",
      "Step: 12470 Train Loss: 0.968204\n",
      "Step: 12480 Train Loss: 0.919451\n",
      "Step: 12490 Train Loss: 0.832026\n",
      "Step: 12500 Train Loss: 0.896943\n",
      "Step: 12510 Train Loss: 0.837005\n",
      "Step: 12520 Train Loss: 0.830015\n",
      "Step: 12530 Train Loss: 0.889752\n",
      "Step: 12540 Train Loss: 1.021579\n",
      "Step: 12550 Train Loss: 0.877983\n",
      "Step: 12560 Train Loss: 0.785408\n",
      "Step: 12570 Train Loss: 0.666658\n",
      "Step: 12580 Train Loss: 0.936109\n",
      "Step: 12590 Train Loss: 1.019447\n",
      "Step: 12600 Train Loss: 0.804220\n",
      "==============================================\n",
      "Step: 12600 Validation Loss: 1.293897\n",
      "==============================================\n",
      "Step: 12610 Train Loss: 1.041540\n",
      "Step: 12620 Train Loss: 0.772264\n",
      "Step: 12630 Train Loss: 0.735689\n",
      "Step: 12640 Train Loss: 0.826759\n",
      "Step: 12650 Train Loss: 0.927102\n",
      "Step: 12660 Train Loss: 0.677845\n",
      "Step: 12670 Train Loss: 0.786732\n",
      "Step: 12680 Train Loss: 0.960945\n",
      "Step: 12690 Train Loss: 0.736601\n",
      "Step: 12700 Train Loss: 0.655619\n",
      "Step: 12710 Train Loss: 0.834261\n",
      "Step: 12720 Train Loss: 0.959365\n",
      "Step: 12730 Train Loss: 0.725632\n",
      "Step: 12740 Train Loss: 0.643787\n",
      "Step: 12750 Train Loss: 0.748801\n",
      "Step: 12760 Train Loss: 0.861951\n",
      "Step: 12770 Train Loss: 0.946275\n",
      "Step: 12780 Train Loss: 0.805669\n",
      "Step: 12790 Train Loss: 0.787793\n",
      "Step: 12800 Train Loss: 0.812274\n",
      "==============================================\n",
      "Step: 12800 Validation Loss: 1.939888\n",
      "==============================================\n",
      "Step: 12810 Train Loss: 0.865593\n",
      "Step: 12820 Train Loss: 0.769806\n",
      "Step: 12830 Train Loss: 0.773260\n",
      "Step: 12840 Train Loss: 0.858722\n",
      "Step: 12850 Train Loss: 0.726951\n",
      "Step: 12860 Train Loss: 0.866802\n",
      "Step: 12870 Train Loss: 0.924634\n",
      "Step: 12880 Train Loss: 1.042428\n",
      "Step: 12890 Train Loss: 0.759895\n",
      "Step: 12900 Train Loss: 1.037501\n",
      "Step: 12910 Train Loss: 0.841101\n",
      "Step: 12920 Train Loss: 1.054197\n",
      "Step: 12930 Train Loss: 0.918306\n",
      "Step: 12940 Train Loss: 0.898912\n",
      "Step: 12950 Train Loss: 1.041956\n",
      "Step: 12960 Train Loss: 0.846651\n",
      "Step: 12970 Train Loss: 0.970441\n",
      "Step: 12980 Train Loss: 0.968706\n",
      "Step: 12990 Train Loss: 0.726233\n",
      "Step: 13000 Train Loss: 0.806085\n",
      "==============================================\n",
      "Step: 13000 Validation Loss: 2.141643\n",
      "==============================================\n",
      "Step: 13010 Train Loss: 0.927394\n",
      "Step: 13020 Train Loss: 0.966097\n",
      "Step: 13030 Train Loss: 0.727343\n",
      "Step: 13040 Train Loss: 0.733328\n",
      "Step: 13050 Train Loss: 0.727410\n",
      "Step: 13060 Train Loss: 0.924790\n",
      "Step: 13070 Train Loss: 1.016115\n",
      "Step: 13080 Train Loss: 0.823266\n",
      "Step: 13090 Train Loss: 0.839760\n",
      "Step: 13100 Train Loss: 0.857882\n",
      "Step: 13110 Train Loss: 0.705391\n",
      "Step: 13120 Train Loss: 0.961377\n",
      "Step: 13130 Train Loss: 1.003819\n",
      "Step: 13140 Train Loss: 0.718102\n",
      "Step: 13150 Train Loss: 0.820474\n",
      "Step: 13160 Train Loss: 0.833425\n",
      "Step: 13170 Train Loss: 0.778240\n",
      "Step: 13180 Train Loss: 0.656193\n",
      "Step: 13190 Train Loss: 0.757559\n",
      "Step: 13200 Train Loss: 0.705803\n",
      "==============================================\n",
      "Step: 13200 Validation Loss: 1.883738\n",
      "==============================================\n",
      "Step: 13210 Train Loss: 0.868262\n",
      "Step: 13220 Train Loss: 1.075742\n",
      "Step: 13230 Train Loss: 0.916259\n",
      "Step: 13240 Train Loss: 0.711160\n",
      "Step: 13250 Train Loss: 0.761839\n",
      "Step: 13260 Train Loss: 0.818493\n",
      "Step: 13270 Train Loss: 1.130505\n",
      "Step: 13280 Train Loss: 0.750396\n",
      "Step: 13290 Train Loss: 0.904033\n",
      "Step: 13300 Train Loss: 0.848838\n",
      "Step: 13310 Train Loss: 0.850645\n",
      "Step: 13320 Train Loss: 0.837684\n",
      "Step: 13330 Train Loss: 0.834269\n",
      "Step: 13340 Train Loss: 1.137669\n",
      "Step: 13350 Train Loss: 0.954711\n",
      "Step: 13360 Train Loss: 0.760800\n",
      "Step: 13370 Train Loss: 0.997069\n",
      "Step: 13380 Train Loss: 0.953721\n",
      "Step: 13390 Train Loss: 0.721970\n",
      "Step: 13400 Train Loss: 0.744144\n",
      "==============================================\n",
      "Step: 13400 Validation Loss: 1.572838\n",
      "==============================================\n",
      "Step: 13410 Train Loss: 0.940409\n",
      "Step: 13420 Train Loss: 0.836667\n",
      "Step: 13430 Train Loss: 0.876596\n",
      "Step: 13440 Train Loss: 0.809903\n",
      "Step: 13450 Train Loss: 1.097988\n",
      "Step: 13460 Train Loss: 0.680507\n",
      "Step: 13470 Train Loss: 0.831713\n",
      "Step: 13480 Train Loss: 0.968242\n",
      "Step: 13490 Train Loss: 0.990282\n",
      "Step: 13500 Train Loss: 0.683698\n",
      "Step: 13510 Train Loss: 0.877304\n",
      "Step: 13520 Train Loss: 0.987731\n",
      "Step: 13530 Train Loss: 0.794455\n",
      "Step: 13540 Train Loss: 0.776209\n",
      "Step: 13550 Train Loss: 0.889092\n",
      "Step: 13560 Train Loss: 0.842864\n",
      "Step: 13570 Train Loss: 0.792210\n",
      "Step: 13580 Train Loss: 0.703339\n",
      "Step: 13590 Train Loss: 1.090570\n",
      "Step: 13600 Train Loss: 0.972540\n",
      "==============================================\n",
      "Step: 13600 Validation Loss: 1.946104\n",
      "==============================================\n",
      "Step: 13610 Train Loss: 0.801872\n",
      "Step: 13620 Train Loss: 0.857448\n",
      "Step: 13630 Train Loss: 0.678729\n",
      "Step: 13640 Train Loss: 0.879405\n",
      "Step: 13650 Train Loss: 0.981688\n",
      "Step: 13660 Train Loss: 0.947586\n",
      "Step: 13670 Train Loss: 0.790980\n",
      "Step: 13680 Train Loss: 0.925223\n",
      "Step: 13690 Train Loss: 0.849691\n",
      "Step: 13700 Train Loss: 0.845470\n",
      "Step: 13710 Train Loss: 0.786692\n",
      "Step: 13720 Train Loss: 0.740029\n",
      "Step: 13730 Train Loss: 0.825760\n",
      "Step: 13740 Train Loss: 1.132826\n",
      "Step: 13750 Train Loss: 0.941560\n",
      "Step: 13760 Train Loss: 0.951254\n",
      "Step: 13770 Train Loss: 0.812151\n",
      "Step: 13780 Train Loss: 1.005852\n",
      "Step: 13790 Train Loss: 0.951814\n",
      "Step: 13800 Train Loss: 1.054588\n",
      "==============================================\n",
      "Step: 13800 Validation Loss: 1.690979\n",
      "==============================================\n",
      "Step: 13810 Train Loss: 0.666543\n",
      "Step: 13820 Train Loss: 0.869375\n",
      "Step: 13830 Train Loss: 0.766366\n",
      "Step: 13840 Train Loss: 0.860870\n",
      "Step: 13850 Train Loss: 0.752566\n",
      "Step: 13860 Train Loss: 0.784989\n",
      "Step: 13870 Train Loss: 0.836411\n",
      "Step: 13880 Train Loss: 0.852826\n",
      "Step: 13890 Train Loss: 0.823271\n",
      "Step: 13900 Train Loss: 0.870905\n",
      "Step: 13910 Train Loss: 0.889919\n",
      "Step: 13920 Train Loss: 1.107952\n",
      "Step: 13930 Train Loss: 1.041876\n",
      "Step: 13940 Train Loss: 0.773957\n",
      "Step: 13950 Train Loss: 0.906749\n",
      "Step: 13960 Train Loss: 0.769346\n",
      "Step: 13970 Train Loss: 1.005878\n",
      "Step: 13980 Train Loss: 0.755405\n",
      "Step: 13990 Train Loss: 0.999086\n",
      "Step: 14000 Train Loss: 0.709842\n",
      "==============================================\n",
      "Step: 14000 Validation Loss: 1.738534\n",
      "==============================================\n",
      "Step: 14010 Train Loss: 0.900016\n",
      "Step: 14020 Train Loss: 1.010551\n",
      "Step: 14030 Train Loss: 0.690784\n",
      "Step: 14040 Train Loss: 0.968203\n",
      "Step: 14050 Train Loss: 0.727736\n",
      "Step: 14060 Train Loss: 0.753510\n",
      "Step: 14070 Train Loss: 0.825504\n",
      "Step: 14080 Train Loss: 0.936168\n",
      "Step: 14090 Train Loss: 0.890821\n",
      "Step: 14100 Train Loss: 0.789145\n",
      "Step: 14110 Train Loss: 0.868864\n",
      "Step: 14120 Train Loss: 0.861103\n",
      "Step: 14130 Train Loss: 0.668254\n",
      "Step: 14140 Train Loss: 0.943911\n",
      "Step: 14150 Train Loss: 0.701003\n",
      "Step: 14160 Train Loss: 0.882860\n",
      "Step: 14170 Train Loss: 0.799851\n",
      "Step: 14180 Train Loss: 1.024191\n",
      "Step: 14190 Train Loss: 0.798963\n",
      "Step: 14200 Train Loss: 0.907433\n",
      "==============================================\n",
      "Step: 14200 Validation Loss: 1.592927\n",
      "==============================================\n",
      "Step: 14210 Train Loss: 0.733220\n",
      "Step: 14220 Train Loss: 0.675577\n",
      "Step: 14230 Train Loss: 0.976712\n",
      "Step: 14240 Train Loss: 0.813104\n",
      "Step: 14250 Train Loss: 0.722241\n",
      "Step: 14260 Train Loss: 0.941841\n",
      "Step: 14270 Train Loss: 0.850599\n",
      "Step: 14280 Train Loss: 0.917492\n",
      "Step: 14290 Train Loss: 0.726618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14300 Train Loss: 0.844922\n",
      "Step: 14310 Train Loss: 0.740525\n",
      "Step: 14320 Train Loss: 0.878893\n",
      "Step: 14330 Train Loss: 0.962457\n",
      "Step: 14340 Train Loss: 0.867303\n",
      "Step: 14350 Train Loss: 0.779611\n",
      "Step: 14360 Train Loss: 0.789077\n",
      "Step: 14370 Train Loss: 0.843503\n",
      "Step: 14380 Train Loss: 0.901817\n",
      "Step: 14390 Train Loss: 0.806828\n",
      "Step: 14400 Train Loss: 0.706466\n",
      "==============================================\n",
      "Step: 14400 Validation Loss: 1.968694\n",
      "==============================================\n",
      "Step: 14410 Train Loss: 0.940099\n",
      "Step: 14420 Train Loss: 0.653280\n",
      "Step: 14430 Train Loss: 0.741208\n",
      "Step: 14440 Train Loss: 0.818459\n",
      "Step: 14450 Train Loss: 0.868914\n",
      "Step: 14460 Train Loss: 0.693972\n",
      "Step: 14470 Train Loss: 0.933930\n",
      "Step: 14480 Train Loss: 0.750868\n",
      "Step: 14490 Train Loss: 0.696258\n",
      "Step: 14500 Train Loss: 0.937413\n",
      "Step: 14510 Train Loss: 0.788274\n",
      "Step: 14520 Train Loss: 0.831934\n",
      "Step: 14530 Train Loss: 0.762043\n",
      "Step: 14540 Train Loss: 0.688181\n",
      "Step: 14550 Train Loss: 0.877637\n",
      "Step: 14560 Train Loss: 0.955303\n",
      "Step: 14570 Train Loss: 0.937015\n",
      "Step: 14580 Train Loss: 0.938030\n",
      "Step: 14590 Train Loss: 0.916951\n",
      "Step: 14600 Train Loss: 0.870036\n",
      "==============================================\n",
      "Step: 14600 Validation Loss: 1.747717\n",
      "==============================================\n",
      "Step: 14610 Train Loss: 0.958197\n",
      "Step: 14620 Train Loss: 0.514594\n",
      "Step: 14630 Train Loss: 0.791615\n",
      "Step: 14640 Train Loss: 0.956554\n",
      "Step: 14650 Train Loss: 0.943343\n",
      "Step: 14660 Train Loss: 0.652272\n",
      "Step: 14670 Train Loss: 1.167460\n",
      "Step: 14680 Train Loss: 0.870433\n",
      "Step: 14690 Train Loss: 0.788960\n",
      "Step: 14700 Train Loss: 0.765365\n",
      "Step: 14710 Train Loss: 0.649092\n",
      "Step: 14720 Train Loss: 0.835370\n",
      "Step: 14730 Train Loss: 0.640055\n",
      "Step: 14740 Train Loss: 1.008757\n",
      "Step: 14750 Train Loss: 0.866157\n",
      "Step: 14760 Train Loss: 0.989164\n",
      "Step: 14770 Train Loss: 0.811401\n",
      "Step: 14780 Train Loss: 0.857775\n",
      "Step: 14790 Train Loss: 0.867485\n",
      "Step: 14800 Train Loss: 0.694820\n",
      "==============================================\n",
      "Step: 14800 Validation Loss: 1.622687\n",
      "==============================================\n",
      "Step: 14810 Train Loss: 0.657421\n",
      "Step: 14820 Train Loss: 0.922724\n",
      "Step: 14830 Train Loss: 0.831797\n",
      "Step: 14840 Train Loss: 0.703601\n",
      "Step: 14850 Train Loss: 0.879632\n",
      "Step: 14860 Train Loss: 0.728206\n",
      "Step: 14870 Train Loss: 0.865471\n",
      "Step: 14880 Train Loss: 0.771697\n",
      "Step: 14890 Train Loss: 0.899154\n",
      "Step: 14900 Train Loss: 0.811100\n",
      "Step: 14910 Train Loss: 0.877099\n",
      "Step: 14920 Train Loss: 0.876937\n",
      "Step: 14930 Train Loss: 0.854739\n",
      "Step: 14940 Train Loss: 1.058295\n",
      "Step: 14950 Train Loss: 0.985720\n",
      "Step: 14960 Train Loss: 0.929936\n",
      "Step: 14970 Train Loss: 0.827977\n",
      "Step: 14980 Train Loss: 0.697653\n",
      "Step: 14990 Train Loss: 0.744734\n",
      "Step: 15000 Train Loss: 0.882967\n",
      "==============================================\n",
      "Step: 15000 Validation Loss: 2.057936\n",
      "==============================================\n",
      "Step: 15010 Train Loss: 0.655753\n",
      "Step: 15020 Train Loss: 0.835084\n",
      "Step: 15030 Train Loss: 0.801738\n",
      "Step: 15040 Train Loss: 0.770332\n",
      "Step: 15050 Train Loss: 0.897343\n",
      "Step: 15060 Train Loss: 0.644038\n",
      "Step: 15070 Train Loss: 0.884452\n",
      "Step: 15080 Train Loss: 0.723691\n",
      "Step: 15090 Train Loss: 0.953070\n",
      "Step: 15100 Train Loss: 0.844310\n",
      "Step: 15110 Train Loss: 0.799538\n",
      "Step: 15120 Train Loss: 0.886134\n",
      "Step: 15130 Train Loss: 0.709872\n",
      "Step: 15140 Train Loss: 0.972833\n",
      "Step: 15150 Train Loss: 0.957737\n",
      "Step: 15160 Train Loss: 0.791809\n",
      "Step: 15170 Train Loss: 0.830135\n",
      "Step: 15180 Train Loss: 0.999662\n",
      "Step: 15190 Train Loss: 0.628520\n",
      "Step: 15200 Train Loss: 0.861904\n",
      "==============================================\n",
      "Step: 15200 Validation Loss: 1.959483\n",
      "==============================================\n",
      "Step: 15210 Train Loss: 0.915390\n",
      "Step: 15220 Train Loss: 0.834250\n",
      "Step: 15230 Train Loss: 0.870026\n",
      "Step: 15240 Train Loss: 0.857285\n",
      "Step: 15250 Train Loss: 0.889779\n",
      "Step: 15260 Train Loss: 0.825498\n",
      "Step: 15270 Train Loss: 0.869560\n",
      "Step: 15280 Train Loss: 0.808278\n",
      "Step: 15290 Train Loss: 0.873120\n",
      "Step: 15300 Train Loss: 0.885318\n",
      "Step: 15310 Train Loss: 0.726009\n",
      "Step: 15320 Train Loss: 0.867736\n",
      "Step: 15330 Train Loss: 1.024449\n",
      "Step: 15340 Train Loss: 0.746465\n",
      "Step: 15350 Train Loss: 0.542582\n",
      "Step: 15360 Train Loss: 0.797434\n",
      "Step: 15370 Train Loss: 0.777362\n",
      "Step: 15380 Train Loss: 0.705931\n",
      "Step: 15390 Train Loss: 0.827685\n",
      "Step: 15400 Train Loss: 0.914026\n",
      "==============================================\n",
      "Step: 15400 Validation Loss: 1.875056\n",
      "==============================================\n",
      "Step: 15410 Train Loss: 0.800440\n",
      "Step: 15420 Train Loss: 1.054368\n",
      "Step: 15430 Train Loss: 0.939800\n",
      "Step: 15440 Train Loss: 0.680956\n",
      "Step: 15450 Train Loss: 0.927255\n",
      "Step: 15460 Train Loss: 0.824806\n",
      "Step: 15470 Train Loss: 0.665319\n",
      "Step: 15480 Train Loss: 0.764702\n",
      "Step: 15490 Train Loss: 0.659917\n",
      "Step: 15500 Train Loss: 0.850064\n",
      "Step: 15510 Train Loss: 0.757569\n",
      "Step: 15520 Train Loss: 0.758450\n",
      "Step: 15530 Train Loss: 0.675031\n",
      "Step: 15540 Train Loss: 1.044438\n",
      "Step: 15550 Train Loss: 0.872411\n",
      "Step: 15560 Train Loss: 0.860684\n",
      "Step: 15570 Train Loss: 0.853483\n",
      "Step: 15580 Train Loss: 0.746956\n",
      "Step: 15590 Train Loss: 0.848801\n",
      "Step: 15600 Train Loss: 0.845433\n",
      "==============================================\n",
      "Step: 15600 Validation Loss: 2.328884\n",
      "==============================================\n",
      "Step: 15610 Train Loss: 0.826810\n",
      "Step: 15620 Train Loss: 0.789740\n",
      "Step: 15630 Train Loss: 0.758773\n",
      "Step: 15640 Train Loss: 0.901547\n",
      "Step: 15650 Train Loss: 0.932529\n",
      "Step: 15660 Train Loss: 0.907962\n",
      "Step: 15670 Train Loss: 0.837736\n",
      "Step: 15680 Train Loss: 0.965442\n",
      "Step: 15690 Train Loss: 0.856299\n",
      "Step: 15700 Train Loss: 0.831182\n",
      "Step: 15710 Train Loss: 0.851977\n",
      "Step: 15720 Train Loss: 0.860073\n",
      "Step: 15730 Train Loss: 0.727534\n",
      "Step: 15740 Train Loss: 0.817201\n",
      "Step: 15750 Train Loss: 0.880861\n",
      "Step: 15760 Train Loss: 0.946853\n",
      "Step: 15770 Train Loss: 0.773998\n",
      "Step: 15780 Train Loss: 0.888988\n",
      "Step: 15790 Train Loss: 0.877886\n",
      "Step: 15800 Train Loss: 0.851858\n",
      "==============================================\n",
      "Step: 15800 Validation Loss: 1.695202\n",
      "==============================================\n",
      "Step: 15810 Train Loss: 0.857184\n",
      "Step: 15820 Train Loss: 0.788638\n",
      "Step: 15830 Train Loss: 0.653808\n",
      "Step: 15840 Train Loss: 0.745488\n",
      "Step: 15850 Train Loss: 0.836024\n",
      "Step: 15860 Train Loss: 0.760877\n",
      "Step: 15870 Train Loss: 0.944241\n",
      "Step: 15880 Train Loss: 0.711013\n",
      "Step: 15890 Train Loss: 0.763778\n",
      "Step: 15900 Train Loss: 0.707379\n",
      "Step: 15910 Train Loss: 0.822274\n",
      "Step: 15920 Train Loss: 0.961527\n",
      "Step: 15930 Train Loss: 0.645458\n",
      "Step: 15940 Train Loss: 0.808753\n",
      "Step: 15950 Train Loss: 0.646314\n",
      "Step: 15960 Train Loss: 0.753036\n",
      "Step: 15970 Train Loss: 0.810692\n",
      "Step: 15980 Train Loss: 0.819377\n",
      "Step: 15990 Train Loss: 0.799177\n",
      "Step: 16000 Train Loss: 0.693657\n",
      "==============================================\n",
      "Step: 16000 Validation Loss: 2.424000\n",
      "==============================================\n",
      "Step: 16010 Train Loss: 0.721544\n",
      "Step: 16020 Train Loss: 0.811334\n",
      "Step: 16030 Train Loss: 0.781121\n",
      "Step: 16040 Train Loss: 0.816342\n",
      "Step: 16050 Train Loss: 0.777038\n",
      "Step: 16060 Train Loss: 0.736213\n",
      "Step: 16070 Train Loss: 0.884458\n",
      "Step: 16080 Train Loss: 0.721152\n",
      "Step: 16090 Train Loss: 0.728603\n",
      "Step: 16100 Train Loss: 0.827005\n",
      "Step: 16110 Train Loss: 0.818800\n",
      "Step: 16120 Train Loss: 0.833165\n",
      "Step: 16130 Train Loss: 0.942008\n",
      "Step: 16140 Train Loss: 0.872850\n",
      "Step: 16150 Train Loss: 0.913398\n",
      "Step: 16160 Train Loss: 0.882763\n",
      "Step: 16170 Train Loss: 0.841868\n",
      "Step: 16180 Train Loss: 0.842038\n",
      "Step: 16190 Train Loss: 0.723247\n",
      "Step: 16200 Train Loss: 0.788481\n",
      "==============================================\n",
      "Step: 16200 Validation Loss: 1.687814\n",
      "==============================================\n",
      "Step: 16210 Train Loss: 0.615819\n",
      "Step: 16220 Train Loss: 0.753823\n",
      "Step: 16230 Train Loss: 0.830450\n",
      "Step: 16240 Train Loss: 0.797841\n",
      "Step: 16250 Train Loss: 0.753486\n",
      "Step: 16260 Train Loss: 0.735014\n",
      "Step: 16270 Train Loss: 0.872966\n",
      "Step: 16280 Train Loss: 0.705571\n",
      "Step: 16290 Train Loss: 0.624591\n",
      "Step: 16300 Train Loss: 0.741276\n",
      "Step: 16310 Train Loss: 0.737041\n",
      "Step: 16320 Train Loss: 0.760571\n",
      "Step: 16330 Train Loss: 0.906696\n",
      "Step: 16340 Train Loss: 0.834992\n",
      "Step: 16350 Train Loss: 0.898301\n",
      "Step: 16360 Train Loss: 0.803183\n",
      "Step: 16370 Train Loss: 0.698750\n",
      "Step: 16380 Train Loss: 0.579229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 16390 Train Loss: 0.799298\n",
      "Step: 16400 Train Loss: 0.766237\n",
      "==============================================\n",
      "Step: 16400 Validation Loss: 1.530668\n",
      "==============================================\n",
      "Step: 16410 Train Loss: 0.687395\n",
      "Step: 16420 Train Loss: 0.692860\n",
      "Step: 16430 Train Loss: 0.774447\n",
      "Step: 16440 Train Loss: 0.955065\n",
      "Step: 16450 Train Loss: 0.604759\n",
      "Step: 16460 Train Loss: 0.724132\n",
      "Step: 16470 Train Loss: 0.736699\n",
      "Step: 16480 Train Loss: 0.800859\n",
      "Step: 16490 Train Loss: 0.731045\n",
      "Step: 16500 Train Loss: 0.796360\n",
      "Step: 16510 Train Loss: 0.733004\n",
      "Step: 16520 Train Loss: 0.796756\n",
      "Step: 16530 Train Loss: 0.781891\n",
      "Step: 16540 Train Loss: 0.900717\n",
      "Step: 16550 Train Loss: 0.739155\n",
      "Step: 16560 Train Loss: 0.695806\n",
      "Step: 16570 Train Loss: 0.798087\n",
      "Step: 16580 Train Loss: 0.799389\n",
      "Step: 16590 Train Loss: 0.792538\n",
      "Step: 16600 Train Loss: 0.843092\n",
      "==============================================\n",
      "Step: 16600 Validation Loss: 1.893348\n",
      "==============================================\n",
      "Step: 16610 Train Loss: 0.798763\n",
      "Step: 16620 Train Loss: 0.778023\n",
      "Step: 16630 Train Loss: 0.725220\n",
      "Step: 16640 Train Loss: 0.651024\n",
      "Step: 16650 Train Loss: 0.656983\n",
      "Step: 16660 Train Loss: 0.830452\n",
      "Step: 16670 Train Loss: 0.894228\n",
      "Step: 16680 Train Loss: 0.686042\n",
      "Step: 16690 Train Loss: 0.768693\n",
      "Step: 16700 Train Loss: 0.759477\n",
      "Step: 16710 Train Loss: 0.813482\n",
      "Step: 16720 Train Loss: 0.804255\n",
      "Step: 16730 Train Loss: 0.851178\n",
      "Step: 16740 Train Loss: 0.763838\n",
      "Step: 16750 Train Loss: 0.712377\n",
      "Step: 16760 Train Loss: 0.864289\n",
      "Step: 16770 Train Loss: 0.798115\n",
      "Step: 16780 Train Loss: 0.733064\n",
      "Step: 16790 Train Loss: 0.709220\n",
      "Step: 16800 Train Loss: 0.874048\n",
      "==============================================\n",
      "Step: 16800 Validation Loss: 2.946891\n",
      "==============================================\n",
      "Step: 16810 Train Loss: 0.935959\n",
      "Step: 16820 Train Loss: 0.846862\n",
      "Step: 16830 Train Loss: 0.837509\n",
      "Step: 16840 Train Loss: 0.830213\n",
      "Step: 16850 Train Loss: 0.893181\n",
      "Step: 16860 Train Loss: 0.685396\n",
      "Step: 16870 Train Loss: 0.611479\n",
      "Step: 16880 Train Loss: 0.948777\n",
      "Step: 16890 Train Loss: 0.827611\n",
      "Step: 16900 Train Loss: 0.586537\n",
      "Step: 16910 Train Loss: 0.733537\n",
      "Step: 16920 Train Loss: 0.711253\n",
      "Step: 16930 Train Loss: 0.812508\n",
      "Step: 16940 Train Loss: 0.707347\n",
      "Step: 16950 Train Loss: 0.708068\n",
      "Step: 16960 Train Loss: 0.836757\n",
      "Step: 16970 Train Loss: 0.871595\n",
      "Step: 16980 Train Loss: 0.750196\n",
      "Step: 16990 Train Loss: 0.832463\n",
      "Step: 17000 Train Loss: 0.803938\n",
      "==============================================\n",
      "Step: 17000 Validation Loss: 2.144461\n",
      "==============================================\n",
      "Step: 17010 Train Loss: 0.799493\n",
      "Step: 17020 Train Loss: 0.770603\n",
      "Step: 17030 Train Loss: 0.898199\n",
      "Step: 17040 Train Loss: 0.843100\n",
      "Step: 17050 Train Loss: 0.790307\n",
      "Step: 17060 Train Loss: 0.902505\n",
      "Step: 17070 Train Loss: 0.770912\n",
      "Step: 17080 Train Loss: 0.704399\n",
      "Step: 17090 Train Loss: 0.671066\n",
      "Step: 17100 Train Loss: 0.946774\n",
      "Step: 17110 Train Loss: 0.787666\n",
      "Step: 17120 Train Loss: 0.762636\n",
      "Step: 17130 Train Loss: 0.867419\n",
      "Step: 17140 Train Loss: 0.652285\n",
      "Step: 17150 Train Loss: 0.734594\n",
      "Step: 17160 Train Loss: 0.731310\n",
      "Step: 17170 Train Loss: 0.800583\n",
      "Step: 17180 Train Loss: 0.760748\n",
      "Step: 17190 Train Loss: 0.768017\n",
      "Step: 17200 Train Loss: 0.857080\n",
      "==============================================\n",
      "Step: 17200 Validation Loss: 2.562090\n",
      "==============================================\n",
      "Step: 17210 Train Loss: 0.812684\n",
      "Step: 17220 Train Loss: 0.753927\n",
      "Step: 17230 Train Loss: 0.627714\n",
      "Step: 17240 Train Loss: 0.822764\n",
      "Step: 17250 Train Loss: 0.632399\n",
      "Step: 17260 Train Loss: 0.811653\n",
      "Step: 17270 Train Loss: 0.672280\n",
      "Step: 17280 Train Loss: 0.795430\n",
      "Step: 17290 Train Loss: 0.822431\n",
      "Step: 17300 Train Loss: 0.639495\n",
      "Step: 17310 Train Loss: 0.832271\n",
      "Step: 17320 Train Loss: 0.660471\n",
      "Step: 17330 Train Loss: 0.866853\n",
      "Step: 17340 Train Loss: 0.687258\n",
      "Step: 17350 Train Loss: 0.823274\n",
      "Step: 17360 Train Loss: 0.925761\n",
      "Step: 17370 Train Loss: 0.738664\n",
      "Step: 17380 Train Loss: 0.819311\n",
      "Step: 17390 Train Loss: 0.673584\n",
      "Step: 17400 Train Loss: 0.817648\n",
      "==============================================\n",
      "Step: 17400 Validation Loss: 1.856966\n",
      "==============================================\n",
      "Step: 17410 Train Loss: 0.686271\n",
      "Step: 17420 Train Loss: 0.843705\n",
      "Step: 17430 Train Loss: 0.875581\n",
      "Step: 17440 Train Loss: 0.744554\n",
      "Step: 17450 Train Loss: 0.939323\n",
      "Step: 17460 Train Loss: 0.660754\n",
      "Step: 17470 Train Loss: 0.831051\n",
      "Step: 17480 Train Loss: 0.733755\n",
      "Step: 17490 Train Loss: 0.829859\n",
      "Step: 17500 Train Loss: 0.543769\n",
      "Step: 17510 Train Loss: 0.672963\n",
      "Step: 17520 Train Loss: 0.831345\n",
      "Step: 17530 Train Loss: 0.668293\n",
      "Step: 17540 Train Loss: 0.851788\n",
      "Step: 17550 Train Loss: 0.904882\n",
      "Step: 17560 Train Loss: 0.806186\n",
      "Step: 17570 Train Loss: 0.756284\n",
      "Step: 17580 Train Loss: 0.771303\n",
      "Step: 17590 Train Loss: 0.797267\n",
      "Step: 17600 Train Loss: 0.836392\n",
      "==============================================\n",
      "Step: 17600 Validation Loss: 1.605151\n",
      "==============================================\n",
      "Step: 17610 Train Loss: 0.802245\n",
      "Step: 17620 Train Loss: 0.876211\n",
      "Step: 17630 Train Loss: 0.709664\n",
      "Step: 17640 Train Loss: 0.796837\n",
      "Step: 17650 Train Loss: 1.075398\n",
      "Step: 17660 Train Loss: 0.851431\n",
      "Step: 17670 Train Loss: 0.733051\n",
      "Step: 17680 Train Loss: 0.830476\n",
      "Step: 17690 Train Loss: 0.856691\n",
      "Step: 17700 Train Loss: 0.552826\n",
      "Step: 17710 Train Loss: 0.815995\n",
      "Step: 17720 Train Loss: 0.826151\n",
      "Step: 17730 Train Loss: 0.731000\n",
      "Step: 17740 Train Loss: 0.861202\n",
      "Step: 17750 Train Loss: 0.667702\n",
      "Step: 17760 Train Loss: 0.823497\n",
      "Step: 17770 Train Loss: 0.727046\n",
      "Step: 17780 Train Loss: 0.846219\n",
      "Step: 17790 Train Loss: 0.641326\n",
      "Step: 17800 Train Loss: 0.895207\n",
      "==============================================\n",
      "Step: 17800 Validation Loss: 1.718197\n",
      "==============================================\n",
      "Step: 17810 Train Loss: 0.763800\n",
      "Step: 17820 Train Loss: 0.736571\n",
      "Step: 17830 Train Loss: 0.862285\n",
      "Step: 17840 Train Loss: 0.758187\n",
      "Step: 17850 Train Loss: 0.826010\n",
      "Step: 17860 Train Loss: 0.763493\n",
      "Step: 17870 Train Loss: 0.859810\n",
      "Step: 17880 Train Loss: 0.732981\n",
      "Step: 17890 Train Loss: 0.690711\n",
      "Step: 17900 Train Loss: 0.805970\n",
      "Step: 17910 Train Loss: 0.824784\n",
      "Step: 17920 Train Loss: 0.741418\n",
      "Step: 17930 Train Loss: 0.672490\n",
      "Step: 17940 Train Loss: 0.730739\n",
      "Step: 17950 Train Loss: 0.774818\n",
      "Step: 17960 Train Loss: 0.649479\n",
      "Step: 17970 Train Loss: 0.999233\n",
      "Step: 17980 Train Loss: 0.778937\n",
      "Step: 17990 Train Loss: 0.710155\n",
      "Step: 18000 Train Loss: 0.671918\n",
      "==============================================\n",
      "Step: 18000 Validation Loss: 1.979946\n",
      "==============================================\n",
      "Step: 18010 Train Loss: 0.884274\n",
      "Step: 18020 Train Loss: 0.725387\n",
      "Step: 18030 Train Loss: 0.905540\n",
      "Step: 18040 Train Loss: 0.893340\n",
      "Step: 18050 Train Loss: 0.870975\n",
      "Step: 18060 Train Loss: 0.780202\n",
      "Step: 18070 Train Loss: 0.813057\n",
      "Step: 18080 Train Loss: 0.988586\n",
      "Step: 18090 Train Loss: 1.003509\n",
      "Step: 18100 Train Loss: 0.913241\n",
      "Step: 18110 Train Loss: 0.700953\n",
      "Step: 18120 Train Loss: 0.704370\n",
      "Step: 18130 Train Loss: 0.788725\n",
      "Step: 18140 Train Loss: 0.727836\n",
      "Step: 18150 Train Loss: 0.608211\n",
      "Step: 18160 Train Loss: 0.806355\n",
      "Step: 18170 Train Loss: 0.828469\n",
      "Step: 18180 Train Loss: 0.607431\n",
      "Step: 18190 Train Loss: 0.704566\n",
      "Step: 18200 Train Loss: 0.753873\n",
      "==============================================\n",
      "Step: 18200 Validation Loss: 2.220489\n",
      "==============================================\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 107, in <module>\n",
      "    train()\n",
      "  File \"train.py\", line 78, in train\n",
      "    y2, _ = sperate_magnitude_phase(data = data_src2_batch)\n",
      "  File \"/home/ecbm4040/nndl_SING/preprocess.py\", line 98, in sperate_magnitude_phase\n",
      "    return np.abs(data), np.angle(data)\n",
      "  File \"<__array_function__ internals>\", line 6, in angle\n",
      "  File \"/home/ecbm4040/envTF24/lib/python3.6/site-packages/numpy/lib/function_base.py\", line 1477, in angle\n",
      "    a = arctan2(zimag, zreal)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba371402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ecbm4040/nndl_SING'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516c19c",
   "metadata": {},
   "source": [
    "# Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5620af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392e3db",
   "metadata": {},
   "source": [
    "# Use to generate splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bde59d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2022-12-17 21:19:24.137711: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "Processing backstreet_boys-i_want_it_that_way.mp3 ...\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fc1c0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ddb7455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipreqs\n",
      "  Downloading pipreqs-0.4.11-py2.py3-none-any.whl (32 kB)\n",
      "Collecting yarg\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Requirement already satisfied: requests in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from yarg->pipreqs) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from requests->yarg->pipreqs) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from requests->yarg->pipreqs) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from requests->yarg->pipreqs) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from requests->yarg->pipreqs) (2021.5.30)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13724 sha256=a22be73901d7000bb01b5281550942436e4f972dc2c6032ae638313c0346b277\n",
      "  Stored in directory: /home/ecbm4040/.cache/pip/wheels/3f/2a/fa/4d7a888e69774d5e6e855d190a8a51b357d77cc05eb1c097c9\n",
      "Successfully built docopt\n",
      "Installing collected packages: yarg, docopt, pipreqs\n",
      "Successfully installed docopt-0.6.2 pipreqs-0.4.11 yarg-0.1.9\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ecbm4040/envTF24/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pipreqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa88b136",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "He trains too long. We will use early stopping as there is not notable improvement past a certain point around past 25k iteration where training loss stagnates between 0.4 and 0.9 and validation loss also stagnats between 1.5 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056bf311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
